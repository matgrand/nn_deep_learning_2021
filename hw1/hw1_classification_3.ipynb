{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: cuda\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt # plotting library\n",
    "import numpy as np # this module is useful to work with numerical arrays\n",
    "import pandas as pd # this module is useful to work with tabular data\n",
    "import random # this module will be used to select random samples from a collection\n",
    "import os # this module will be used just to create directories in the local filesystem\n",
    "from tqdm import tqdm # this module is useful to plot progress bars\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from sklearn.model_selection import KFold # this module is useful to split data into training and test sets\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "\n",
    "# Check if the GPU is available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Selected device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset : Dataset FashionMNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: classifier_data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "Test dataset  : Dataset FashionMNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: classifier_data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "PyTorch tensor shape: torch.Size([1, 28, 28])\n",
      "PyTorch tensor type: torch.float32\n"
     ]
    }
   ],
   "source": [
    "train_dataset = torchvision.datasets.FashionMNIST('classifier_data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_dataset  = torchvision.datasets.FashionMNIST('classifier_data', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "print(f\"Train dataset : {train_dataset}\")\n",
    "print(f\"Test dataset  : {test_dataset}\")\n",
    "\n",
    "label_names=['t-shirt','trouser','pullover','dress','coat','sandal','shirt',\n",
    "             'sneaker','bag','boot']\n",
    "sample_index = 0\n",
    "num_labels = len(label_names)\n",
    "image = train_dataset[sample_index][0]\n",
    "label = label_names[train_dataset[sample_index][1]]\n",
    "\n",
    "print(f'PyTorch tensor shape: {image.shape}')\n",
    "print(f'PyTorch tensor type: {image.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST BATCH SHAPE\n",
      "Test dataloader size: 1 batches\n",
      "\t Data: torch.Size([10000, 1, 28, 28])\n",
      "\t Labels: torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "# # Define train dataloader\n",
    "# train_dataloader = DataLoader(train_ds, batch_size=256, shuffle=False) # shuffle=True\n",
    "\n",
    "# # Define validation dataloader\n",
    "# validation_dataloader = DataLoader(validation_ds, batch_size=256, shuffle=False) # shuffle=True\n",
    "\n",
    "# Define test dataloader\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False) #try big bs\n",
    "\n",
    "\n",
    "# batch_data, batch_labels = next(iter(train_dataloader))\n",
    "# print(f\"TRAIN BATCH SHAPE\")\n",
    "# print(f'Train dataloader size: {len(train_dataloader)} batches')\n",
    "# print(f\"\\t Data: {batch_data.shape}\")\n",
    "# print(f\"\\t Labels: {batch_labels.shape}\")\n",
    "\n",
    "# batch_data, batch_labels = next(iter(validation_dataloader))\n",
    "# print(f\"VALIDATION BATCH SHAPE\")\n",
    "# print(f'Validation dataloader size: {len(validation_dataloader)} batches')\n",
    "# print(f\"\\t Data: {batch_data.shape}\")\n",
    "# print(f\"\\t Labels: {batch_labels.shape}\")\n",
    "\n",
    "batch_data, batch_labels = next(iter(test_dataloader))\n",
    "print(f\"TEST BATCH SHAPE\")\n",
    "print(f'Test dataloader size: {len(test_dataloader)} batches')\n",
    "print(f\"\\t Data: {batch_data.shape}\")\n",
    "print(f\"\\t Labels: {batch_labels.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#good convolutinal neural network architecture, 88% accuracy with 150 epochs, v1\n",
    "class myCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        ### Convolutional section\n",
    "        self.conv = nn.Sequential(\n",
    "            # First convolutional layer\n",
    "            nn.Conv2d(in_channels= 1, out_channels=6, kernel_size=5),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            # Second convolutional layer\n",
    "            nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        ### Flatten layer\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "\n",
    "        ### Linear section\n",
    "        self.lin = nn.Sequential(\n",
    "            # First linear layer\n",
    "            nn.Linear(in_features=12*4*4, out_features=64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            # Second linear\n",
    "            nn.Linear(in_features=64, out_features=32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=0.5),\n",
    "\n",
    "            nn.Linear(in_features=32, out_features=10),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            # we don't need softmax since we'll use cross entropy loss\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Apply convolutions\n",
    "        x = self.conv(x)\n",
    "        # Flatten\n",
    "        x = self.flatten(x)\n",
    "        # # Apply linear layers\n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_epoch(model, dataloader, loss_fn, optimizer, device):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    # Initialize the loss\n",
    "    running_loss = 0\n",
    "    train_loss = []\n",
    "    # Loop over the training batches\n",
    "    for (data, label) in dataloader:\n",
    "        # target = onehot encoding of label\n",
    "        target = torch.eye(10)[label] \n",
    "        # Move the input and target data to the selected device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Compute the output\n",
    "        output = model(data)\n",
    "        assert output.shape == target.shape\n",
    "        # Compute the loss\n",
    "        loss = loss_fn(output, target)\n",
    "        # Compute the gradients\n",
    "        loss.backward()\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "        #batch loss\n",
    "        loss_batch = loss.detach().cpu().numpy()\n",
    "        train_loss.append(loss_batch)\n",
    "    # Return the average training loss\n",
    "    train_loss = np.mean(train_loss)\n",
    "    #print(f\"Training loss: {train_loss}\")\n",
    "    return train_loss\n",
    "\n",
    "#validation function\n",
    "def validate_epoch(model, dataloader, loss_fn, device):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    # Initialize the validation loss\n",
    "    val_loss = []\n",
    "    # Loop over the validation batches\n",
    "    with torch.no_grad():\n",
    "        for (data, label) in dataloader:\n",
    "            # target = onehot encoding of label\n",
    "            target = torch.eye(10)[label] \n",
    "            # Move the input and target data to the selected device\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # Compute the output\n",
    "            output = model(data)\n",
    "            assert output.shape == target.shape\n",
    "            # Compute the loss\n",
    "            loss = loss_fn(output, target)\n",
    "            #batch loss\n",
    "            loss_batch = loss.detach().cpu().numpy()\n",
    "            val_loss.append(loss_batch)\n",
    "    # Return the average validation loss\n",
    "    val_loss = np.mean(val_loss)\n",
    "    #print(f\"Validation loss: {val_loss}\")\n",
    "    return val_loss\n",
    "\n",
    "#reset weights function\n",
    "def reset_weights(model):\n",
    "    for layer in model.modules():\n",
    "        if isinstance(layer, nn.Linear) or isinstance(layer, nn.Conv2d):\n",
    "            layer.reset_parameters()\n",
    "\n",
    "# plot and save validation loss\n",
    "def plot_and_save_losses_and_accuracy(comb_val_losses, model_name):\n",
    "    fig = plt.figure(figsize=(8,3))\n",
    "    plt.plot(comb_val_losses, label='Validation loss', color='red')\n",
    "    plt.ylim(0,2)\n",
    "    plt.title(f\"{model_name} Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    fig.savefig(f\"images/{model_name}_val_loss.eps\", format=\"eps\", dpi=1000, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "#get the percentage of correct predictions on the test set\n",
    "def get_accuracy(model, test_dataloader, loss_fn, device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for (data, label) in test_dataloader:\n",
    "            # target = onehot encoding of label\n",
    "            target = torch.eye(10)[label]\n",
    "            # Move the input and target data to the selected device\n",
    "            data, label, target = data.to(device), label.to(device), target.to(device)\n",
    "            # Compute the output\n",
    "            output = model(data)\n",
    "            assert output.shape == target.shape\n",
    "            # Compute the loss\n",
    "            losses.append(loss_fn(output, target).detach().cpu().numpy())\n",
    "            # Get the index of the max log-probability\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            # Add to the total number of correct predictions\n",
    "            correct += pred.eq(label.view_as(pred)).sum().item()\n",
    "            # Add to the total number of predictions\n",
    "            total += data.shape[0]\n",
    "    # Return the accuracy and test loss\n",
    "    test_loss = np.mean(losses)\n",
    "    return correct/total, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation Training and Hyperparameters Tuning\n",
    "Note: in this case weights are not reset at every new fold, otherwise the training would take too long. This makes the validation loss not 100% correct, and we need to take that into account when looking at the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "## Parameters\n",
    "#batch size\n",
    "batch_sizes = [256, 1024]#[32, 64, 128, 256, 512, 1024]\n",
    "#learning rate\n",
    "learning_rates = [5e-4, 1e-3, 5e-3, 1e-2] #[5e-4, 1e-3, 5e-3, 1e-2]\n",
    "#optimiizer\n",
    "optimizers = [torch.optim.Adam] #[torch.optim.Adam, torch.optim.SGD]\n",
    "optimizer_names = [\"Adam\"]\n",
    "#epochs ## NOTE: the total number of epochs is epochs*k_folds\n",
    "epochs = 10\n",
    "#k-folds\n",
    "k_folds = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________1/8_______________________\n",
      "BS: 256, lr: 5e-04, optim: Adam, epochs: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:21<00:00,  8.11s/it]\n",
      "100%|██████████| 10/10 [01:22<00:00,  8.21s/it]\n",
      "100%|██████████| 10/10 [01:27<00:00,  8.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name: CNN_256_Adam_5e-04\n",
      "Test loss: 0.4918\n",
      "Test accuracy: 80.5700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________2/8_______________________\n",
      "BS: 256, lr: 1e-03, optim: Adam, epochs: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:24<00:58,  8.33s/it]"
     ]
    }
   ],
   "source": [
    "# losses = np.zeros((len(batch_sizes), len(learning_rates), len(optimizers), epochs))\n",
    "losses = np.zeros((len(batch_sizes), len(learning_rates), len(optimizers), epochs*k_folds))\n",
    "num_tot_combinations = len(batch_sizes) * len(learning_rates) * len(optimizers)\n",
    "comb = 0\n",
    "for b, batch_size in enumerate(batch_sizes):\n",
    "    for l, lr in enumerate(learning_rates):\n",
    "        for o, (optim, optim_name) in enumerate(zip(optimizers, optimizer_names)):\n",
    "            print(f\"__________________{comb+1}/{num_tot_combinations}_______________________\")\n",
    "            print(f\"BS: {batch_size}, optim: {optimizer_names[o]}, lr: {lr:.0e}, epochs: {epochs*k_folds}\")\n",
    "            comb += 1\n",
    "            #create model\n",
    "            model = myCNN().to(device)\n",
    "            #create loss function\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            #create optimizer\n",
    "            optimizer = optim(model.parameters(), lr=lr)\n",
    "            #K-fold\n",
    "            kf = KFold(n_splits=k_folds, shuffle=True)\n",
    "            #comb_val_losses = np.zeros(epochs)\n",
    "            comb_val_losses = []\n",
    "            for fold, (train_ids, val_ids) in enumerate(kf.split(train_dataset)):\n",
    "                #reset weights\n",
    "                #reset_weights(model) #no reset\n",
    "                #create dataloaders\n",
    "                train_dataloader = DataLoader(train_dataset, batch_size=batch_size, \n",
    "                                        sampler=SubsetRandomSampler(train_ids))\n",
    "                val_dataloader = DataLoader(train_dataset, batch_size=len(val_ids), #try big bs for val\n",
    "                                        sampler=SubsetRandomSampler(val_ids))\n",
    "                #train model\n",
    "                #val_loss_log = [] #not needed anymore\n",
    "                for epoch in tqdm(range(epochs)):\n",
    "                    train_loss = train_epoch(model, train_dataloader, loss_fn, optimizer, device)\n",
    "                    val_loss = validate_epoch(model, val_dataloader, loss_fn, device)\n",
    "                    #val_loss_log.append(val_loss) #not needed anymore\n",
    "                    comb_val_losses.append(val_loss)\n",
    "                #comb_val_losses += np.array(val_loss_log) / k_folds #not needed anymore\n",
    "            #store losses\n",
    "            comb_val_losses = np.array(comb_val_losses)\n",
    "            losses[b, l, o, :] = comb_val_losses\n",
    "            #complete training on the whole dataset  #not needed anymore\n",
    "            #reset_weights(model) #no reset\n",
    "            # we use the training already done\n",
    "            # train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            # for epoch in tqdm(range(epochs)):\n",
    "            #     _ = train_epoch(model, train_dataloader, loss_fn, optimizer, device)\n",
    "\n",
    "            #plot and save losses\n",
    "            model_name = f\"CNN_{batch_size}_{optim_name}_{lr:.0e}\"\n",
    "            print(f\"model name: {model_name}\")\n",
    "            accuracy, test_loss = get_accuracy(model, test_dataloader, loss_fn, device)\n",
    "            print(f\"Test loss: {test_loss:.4f}\")\n",
    "            print(f\"Test accuracy: {(accuracy*100):.4f}\")\n",
    "            plot_and_save_losses_and_accuracy(comb_val_losses, model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Instantiate the model\n",
    "cnn = myCNN().to(device)\n",
    "\n",
    "# define the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "#define optimizer\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decide to train or not\n",
    "load_good_model = False # if True do not train a new model, if False train a new model\n",
    "good_model_path = \"good_models/cnn_v1_epoch_10.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a folder called training to save the model\n",
    "import pickle\n",
    "if not load_good_model:\n",
    "    if not os.path.exists('training'):\n",
    "        os.makedirs('training')\n",
    "    #clear the training folder\n",
    "    if os.listdir('training'):\n",
    "        for f in os.listdir('training'):\n",
    "            os.remove(os.path.join('training', f))\n",
    "\n",
    "# early stopping helper function\n",
    "def early_stopping(latest_val_losses, best_loss, model, cnt, epoch, increment=0.08, patience=5):\n",
    "    if epoch < 5:\n",
    "        return best_loss, cnt, False\n",
    "    curr_loss = np.mean(latest_val_losses)\n",
    "    if curr_loss < best_loss:\n",
    "        best_loss = curr_loss\n",
    "        #save the model\n",
    "        torch.save(model.state_dict(), f\"training/cnn_epoch_{epoch+1}.pth\")\n",
    "    elif curr_loss > (1+increment)*best_loss:\n",
    "        cnt += 1\n",
    "        if cnt >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch}\")\n",
    "            return best_loss, cnt, True\n",
    "    else:  \n",
    "        cnt = 0\n",
    "    return best_loss, cnt, False           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "if not load_good_model:\n",
    "    num_epochs = 5 #150\n",
    "    #for early stopping\n",
    "    early_stopping_cnt = 0\n",
    "    best_loss = np.inf \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        # Train the model\n",
    "        train_loss = train_epoch(cnn, train_dataloader, loss_fn, optimizer, device)\n",
    "        # Validate the model\n",
    "        val_loss = validate_epoch(cnn, test_dataloader, loss_fn, device)\n",
    "        print(f\"Validation loss: {val_loss}\")\n",
    "        # Append the losses\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # early stopping and saving the model\n",
    "        best_loss, early_stopping_cnt, early_stopping_flag = early_stopping(val_losses, best_loss, cnn, early_stopping_cnt, epoch)\n",
    "    \n",
    "    # Save the losses\n",
    "    with open('training/losses.pkl', 'wb') as f:\n",
    "        pickle.dump([train_losses, val_losses], f)\n",
    "else:\n",
    "    #load the model\n",
    "    cnn.load_state_dict(torch.load(good_model_path))\n",
    "    #load the losses\n",
    "    with open('good_models/losses.pkl', 'rb') as f:\n",
    "        [train_losses, val_losses] = pickle.load(f)\n",
    "    #test the model\n",
    "    test_loss = validate_epoch(cnn, test_dataloader, loss_fn, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses and model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation losses\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.plot(train_losses, label='Training loss')\n",
    "ax.plot(val_losses, label='Validation loss')\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss = validate_epoch(cnn, test_dataloader, loss_fn, device) \n",
    "print(f\"Test loss: {test_loss}\")\n",
    "print(f\"Test accuracy: {100*get_accuracy(cnn, test_dataloader, device)} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get all predictions\n",
    "def get_predictions(model, dataloader, device):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    # Initialize the predictions\n",
    "    predictions = []\n",
    "    # Loop over the test batches\n",
    "    with torch.no_grad():\n",
    "        for (data, label) in tqdm(dataloader):\n",
    "            # Move the input and target data to the selected device\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            # Compute the output\n",
    "            output = model(data)\n",
    "            # Get the index of the max log-probability\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            # Add to the predictions\n",
    "            predictions.extend(pred.cpu().numpy().tolist())\n",
    "    return predictions\n",
    "\n",
    "#get train dataset predictions\n",
    "train_predictions = get_predictions(cnn, train_dataloader, device)\n",
    "# get test dataset predictions\n",
    "test_predictions = get_predictions(cnn, test_dataloader, device)\n",
    "\n",
    "#get the labels\n",
    "train_labels = []\n",
    "for data, label in tqdm(train_dataloader): #note: to have a reasonable cm, dataloader needs to be without shuffle\n",
    "    train_labels.extend(label.numpy())\n",
    "\n",
    "test_labels = []\n",
    "for data, label in tqdm(test_dataloader):\n",
    "    test_labels.extend(label.numpy())\n",
    "\n",
    "print(f\"Train labels: {train_labels[:10]}\")\n",
    "print(f\"Train predictions: {train_predictions[:10]}\")\n",
    "print(f\"Test labels: {test_labels[:10]}\")\n",
    "print(f\"Test predictions: {test_predictions[:10]}\")\n",
    "\n",
    "# calculate confusion matrix for train and test set \n",
    "import sklearn.metrics as metrics\n",
    "cm_train = metrics.confusion_matrix(train_labels, train_predictions)\n",
    "cm_test = metrics.confusion_matrix(test_labels, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "    import itertools\n",
    "    accuracy = np.trace(cm) / np.sum(cm).astype('float')\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(cm_train, target_names=label_names, title='Confusion matrix - Train set')\n",
    "plot_confusion_matrix(cm_test, target_names=label_names, title='Confusion matrix - Test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, shirts can be confused more easily with t-shirts, coats and pullover. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## VISUALIZE WEIGHT HISTOGRAMS, ACTIVATION PROFILES, AND RECEPTIVE FIELDS"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "90f6c143e8a87fb0ac430896b2414bede909786474d0833e4fd2f6aa8ee32104"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('DL_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
