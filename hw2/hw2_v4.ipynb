{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOMEWORK 2 NEURAL NETWORKS AND DEEP LEARNING\n",
    "\n",
    "---\n",
    "A.A. 2021/22 (6 CFU) - Dr. Alberto Testolin, Dr. Umberto Michieli\n",
    "---\n",
    "Student: Matteo Grandin\n",
    "---\n",
    "id: 2020374"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General overview\n",
    " In this homework you will learn how to implement and test neural network models for\n",
    "solving unsupervised problems. For simplicity and to allow continuity with the kind of data you have seen\n",
    "before, the homework will be based on images of FashionMNIST. However, you can optionally explore\n",
    "different image collections (e.g., Caltech or Cifar) or other datasets based on your interests. The basic tasks\n",
    "for the homework will require to test and analyze the convolutional autoencoder implemented during the\n",
    "Lab practice. If you prefer, you can opt for a fully-connected autoencoder, which should achieve similar\n",
    "performance considering the relatively small size of the FashionMNIST images. As for the previous\n",
    "homework, you should explore the use of advanced optimizers and regularization methods. Learning\n",
    "hyperparameters should be tuned using appropriate search procedures, and final accuracy should be\n",
    "evaluated using a cross-validation setup. More advanced tasks will require the exploration of denoising and\n",
    "variational / adversarial architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional autoencoder\n",
    "- implement and test (convolutional) autoencoder, reporting the trend of reconstruction loss and\n",
    "some examples of image reconstruction; explore advanced optimizers and regularization methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOTEBOOK CONTROLS\n",
    "perform_grid_search = False\n",
    "load_good_model = True #load model from file, if false retrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # plotting library\n",
    "import numpy as np # this module is useful to work with numerical arrays\n",
    "import pandas as pd # this module is useful to work with tabular data\n",
    "import random # this module will be used to select random samples from a collection\n",
    "import os # this module will be used just to create directories in the local filesystem\n",
    "from tqdm import tqdm # this module is useful to plot progress bars\n",
    "from sklearn.model_selection import KFold # this module is useful to split data into training and test sets\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import pickle\n",
    "\n",
    "# Check if the GPU is available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "#device = torch.device(\"cpu\") #for debugging\n",
    "print(f'Selected device: {device}')\n",
    "\n",
    "if not os.path.exists('data/training'):\n",
    "    os.makedirs('data/training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset\n",
    "# training and validation will be performed on the training dataset\n",
    "train_dataset = torchvision.datasets.FashionMNIST('data', train=True, download=True)\n",
    "# test dataset will only be used for evaluating final model performance\n",
    "test_dataset  = torchvision.datasets.FashionMNIST('data', train=False, download=True)\n",
    "\n",
    "label_names=['t-shirt','trouser','pullover','dress','coat','sandal','shirt',\n",
    "             'sneaker','bag','boot']\n",
    "num_labels = len(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data transformation\n",
    "train_transform = transforms.Compose([\n",
    "    # OneHotEncoder(num_classes=10),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    # OneHotEncoder(num_classes=10),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Set the train transform\n",
    "train_dataset.transform = train_transform\n",
    "# Set the test transform\n",
    "test_dataset.transform = test_transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model definition\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, encoded_space_dim):\n",
    "        super().__init__()\n",
    "        ### Convolutional section\n",
    "        self.encoder_cnn = nn.Sequential(\n",
    "            # First convolutional layer\n",
    "            nn.Conv2d(in_channels= 1, out_channels=8, kernel_size=3, \n",
    "                      stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            # Second convolutional layer\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, \n",
    "                      stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            # Third convolutional layer\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, \n",
    "                      stride=2, padding=0),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        ### Flatten layer\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        ### Linear section\n",
    "        self.encoder_lin = nn.Sequential(\n",
    "            # First linear layer\n",
    "            nn.Linear(in_features=32*3*3, out_features=64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            # Second linear layer\n",
    "            nn.Linear(in_features=64, out_features=32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            #third linear layer\n",
    "            nn.Linear(in_features=32, out_features=encoded_space_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        # Apply convolutions\n",
    "        x = self.encoder_cnn(x)\n",
    "        # Flatten\n",
    "        x = self.flatten(x)\n",
    "        # # Apply linear layers\n",
    "        x = self.encoder_lin(x)\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, encoded_space_dim):\n",
    "        super().__init__()\n",
    "        ### Linear section\n",
    "        self.decoder_lin = nn.Sequential(\n",
    "            # First linear layer\n",
    "            nn.Linear(in_features=encoded_space_dim, out_features=32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            # Second linear layer\n",
    "            nn.Linear(in_features=32, out_features=64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            # Second linear layer\n",
    "            nn.Linear(in_features=64, out_features=3*3*32),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        ### Unflatten\n",
    "        self.unflatten = nn.Unflatten(dim=1, unflattened_size=(32, 3, 3))\n",
    "        ### Convolutional section\n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            # First transposed convolution\n",
    "            nn.ConvTranspose2d(in_channels=32, out_channels=16, kernel_size=3, \n",
    "                               stride=2, output_padding=0),\n",
    "            nn.ReLU(True),\n",
    "            # Second transposed convolution\n",
    "            nn.ConvTranspose2d(in_channels=16, out_channels=8, kernel_size=3, \n",
    "                               stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(True),\n",
    "            # Third transposed convolution\n",
    "            nn.ConvTranspose2d(in_channels=8, out_channels=1, kernel_size=3, \n",
    "                               stride=2, padding=1, output_padding=1)\n",
    "        ) \n",
    "    def forward(self, x):\n",
    "        # Apply linear layers\n",
    "        x = self.decoder_lin(x)\n",
    "        # Unflatten\n",
    "        x = self.unflatten(x)\n",
    "        # Apply transposed convolutions\n",
    "        x = self.decoder_conv(x)\n",
    "        # Apply a sigmoid to force the output to be between 0 and 1 (valid pixel values)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training function\n",
    "def train_epoch(encoder, decoder, device, dataloader, loss_fn, optimizer, apply_softmax=False):\n",
    "    # Set train mode for both the encoder and the decoder\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    train_loss = []\n",
    "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n",
    "    for (image_batch, _) in dataloader: # with \"_\" we just ignore the labels (the second element of the dataloader tuple)\n",
    "        # Move tensor to the proper device\n",
    "        image_batch = image_batch.to(device)\n",
    "        # Encode data\n",
    "        encoded_data = encoder(image_batch)\n",
    "        if apply_softmax:\n",
    "            encoded_data = F.softmax(encoded_data, dim=1)\n",
    "        # Decode data\n",
    "        decoded_data = decoder(encoded_data)\n",
    "        # Evaluate loss\n",
    "        loss = loss_fn(decoded_data, image_batch)\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Add loss to the list\n",
    "        train_loss.append(loss.item())\n",
    "    train_loss = np.mean(train_loss)\n",
    "    #print(f\"Batch Train loss: {train_loss}\")\n",
    "    return train_loss\n",
    "\n",
    "### Testing function\n",
    "def validate_epoch(encoder, decoder, device, dataloader, loss_fn, apply_softmax=False):\n",
    "    # Set evaluation mode for encoder and decoder\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    with torch.no_grad(): # No need to track the gradients\n",
    "        # Define the lists to store the outputs for each batch\n",
    "        conc_out = []\n",
    "        conc_label = []\n",
    "        for (image_batch, _) in dataloader:\n",
    "            # Move tensor to the proper device\n",
    "            image_batch = image_batch.to(device)\n",
    "            # Encode data\n",
    "            encoded_data = encoder(image_batch)\n",
    "            if apply_softmax:\n",
    "                encoded_data = F.softmax(encoded_data, dim=1)\n",
    "            # Decode data\n",
    "            decoded_data = decoder(encoded_data)\n",
    "            # Append the network output and the original image to the lists\n",
    "            conc_out.append(decoded_data.cpu())\n",
    "            conc_label.append(image_batch.cpu())\n",
    "        # Create a single tensor with all the values in the lists\n",
    "        conc_out = torch.cat(conc_out)\n",
    "        conc_label = torch.cat(conc_label) \n",
    "        # Evaluate global loss\n",
    "        val_loss = loss_fn(conc_out, conc_label)\n",
    "        #print(f\"Batch Validation loss: {val_loss}\")\n",
    "    return val_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#useful functions\n",
    "def plot_losses(train_losses, val_losses, title, save_name=None, label1=\"Training loss\", label2=\"Validation loss\", max_y=0.2):\n",
    "    fig = plt.figure(figsize=(12,4))\n",
    "    plt.plot(train_losses, label=label1)\n",
    "    plt.plot(val_losses, label=label2)\n",
    "    plt.ylim(0,max_y)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    if save_name is None:\n",
    "        save_name = title\n",
    "    fig.savefig(\"images/\"+save_name+\".eps\",format=\"eps\", dpi=1200, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "def reset_weights(model):\n",
    "    for layer in model.modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize hyperparameters\n",
    "- 1 pt: optimize hyperparameters using grid/random search or automatic tuning tools (e.g., Optuna)\n",
    "- final accuracy should be evaluated using a cross-validation setup (concatenate training and test set like in here, than evaluate accuracy for each fold and take the avg https://www.machinecurve.com/index.php/2021/02/03/how-to-use-k-fold-cross-validation-with-pytorch/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train loop\n",
    "def train_loop(param_combinations, k_folds, num_epochs, train_dataset, device=\"cuda\"):\n",
    "\n",
    "    # initialize encoder and decoder\n",
    "    enc,dec = Encoder(1), Decoder(1)\n",
    "\n",
    "    val_losses = []\n",
    "\n",
    "    for comb, params in enumerate(param_combinations):\n",
    "        print(f\"______________________{comb+1}/{len(param_combinations)}_______________________\")\n",
    "        lr, optimizer, wd, encoded_space_dim = params\n",
    "        print(optimizer.__name__)\n",
    "        comb_name = f\"{optimizer.__name__}_lr_{lr:.0e}_wd_{wd:.0e}_esd_{encoded_space_dim}\"\n",
    "        print(f\"Parameter combination {comb+1}: {comb_name}\")\n",
    "\n",
    "        # initialize models\n",
    "        enc = Encoder(encoded_space_dim)\n",
    "        dec = Decoder(encoded_space_dim)\n",
    "        #reset weights\n",
    "        enc.apply(reset_weights)\n",
    "        dec.apply(reset_weights)\n",
    "        # initialize optimizer\n",
    "        params_to_optimize = [\n",
    "            {'params': enc.parameters()},\n",
    "            {'params': dec.parameters()}\n",
    "        ]\n",
    "        optim = optimizer(params_to_optimize, lr=lr, weight_decay=wd)\n",
    "        if optimizer == torch.optim.SGD:\n",
    "            optim.param_groups[0]['momentum'] = 0.9 # SGD momentum, SGD is bad\n",
    "        # initialize loss function\n",
    "        loss_fn = nn.MSELoss()\n",
    "        # move to device\n",
    "        enc.to(device)\n",
    "        dec.to(device)\n",
    "\n",
    "        ## train the model\n",
    "        # perform cross validation \n",
    "        kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "        #initialize trainining and validation losses\n",
    "        # comb_train_losses = np.zeros(num_epochs)\n",
    "        # comb_val_losses = np.zeros(num_epochs)\n",
    "        comb_train_losses = []\n",
    "        comb_val_losses = []\n",
    "        for fold, (train_ids, validation_ids) in enumerate(kfold.split(train_dataset)):\n",
    "            #print(f\"Fold {fold}\")\n",
    "            # #reset weights # see comment in the above cell\n",
    "            # enc.apply(reset_weights)\n",
    "            # dec.apply(reset_weights)\n",
    "            # Sample elements randomly from a given list of ids, no replacement.\n",
    "            train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "            validation_subsampler = torch.utils.data.SubsetRandomSampler(validation_ids)\n",
    "            # dataloaders\n",
    "            train_dataloader = DataLoader(train_dataset, batch_size=256, sampler=train_subsampler) \n",
    "            validation_dataloader = DataLoader(train_dataset, batch_size=256, sampler=validation_subsampler) \n",
    "            # train the model\n",
    "            # i_train_losses = []\n",
    "            # i_val_losses = []\n",
    "            for epoch in tqdm(range(num_epochs)):\n",
    "                #print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "                #train\n",
    "                epoch_train_loss = train_epoch(enc, dec, device, train_dataloader, loss_fn, optim)\n",
    "                #validate\n",
    "                epoch_val_loss = validate_epoch(enc, dec, device, validation_dataloader, loss_fn)\n",
    "                # store losses\n",
    "                # i_train_losses.append(epoch_train_loss)\n",
    "                # i_val_losses.append(epoch_val_loss)\n",
    "                comb_train_losses.append(epoch_train_loss)\n",
    "                comb_val_losses.append(epoch_val_loss)\n",
    "                # # save model\n",
    "                # torch.save(enc.state_dict(), f\"data/training/encoder_{comb}_{fold}_{epoch}.pt\")\n",
    "                # torch.save(dec.state_dict(), f\"data/training/decoder_{comb}_{fold}_{epoch}.pt\")\n",
    "            \n",
    "            # comb_train_losses += np.array(i_train_losses)/k_folds\n",
    "            # comb_val_losses += np.array(i_val_losses)/k_folds\n",
    "        plot_losses(comb_train_losses, comb_val_losses, \n",
    "                        title=f\"{optimizer.__name__} - lr:{lr:.0e} - weight decay: {wd:.0e} - ESD: {encoded_space_dim}\",\n",
    "                        save_name=f\"loss_{comb+1}_{comb_name}_{k_folds*num_epochs}\")\n",
    "        # train and validation loss for paramters combination\n",
    "        comb_train_loss = comb_train_losses[-1] # last epoch\n",
    "        comb_val_loss = comb_val_losses[-1] # last epoch\n",
    "        val_losses.append(comb_val_loss)\n",
    "        print(f\"Combination {comb+1} Train loss: {comb_train_loss}\")\n",
    "        print(f\"Combination {comb+1} Validation loss: {comb_val_loss}\")\n",
    "\n",
    "        # # train the model on all the trainign data\n",
    "        # enc.apply(reset_weights)\n",
    "        # dec.apply(reset_weights)\n",
    "        # for epoch in tqdm(range(num_epochs)):\n",
    "        #     #print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        #     #train\n",
    "        #     epoch_train_loss = train_epoch(enc, dec, device, train_dataloader, loss_fn, optim)\n",
    "\n",
    "        # save model\n",
    "        torch.save(enc.state_dict(), f\"data/training/encoder_{comb}_final_{num_epochs*k_folds}.pt\")\n",
    "        torch.save(dec.state_dict(), f\"data/training/decoder_{comb}_final_{num_epochs*k_folds}.pt\")\n",
    "        # save losses\n",
    "        with open(f\"data/training/losses_{comb}.pkl\", 'wb') as f:\n",
    "            pickle.dump([comb_train_losses, comb_val_losses], f)\n",
    "\n",
    "    return enc, dec, val_losses #return last, in case there is only one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once again, even if it's not perfectly accurate, weights will not be reset every fold\n",
    "# and losses between folds will be concatenated, not averaged.\n",
    "# this will lower the training time. The effective number of epochs is k_folds * num_epochs\n",
    "k_folds = 4\n",
    "num_epochs = 15 #15*4 ~ 3.5h for 18 combinations\n",
    "\n",
    "#generate parameters combinations\n",
    "learning_rates = [5e-3, 1e-3, 5e-4] #[5e-3, 1e-3, 5e-4]\n",
    "optimizers = [torch.optim.Adam] #[torch.optim.Adam, torch.optim.SGD]\n",
    "optimizer_names = [\"adam\"] #[\"adam\", \"sgd\"]\n",
    "weight_decays = [1e-5, 1e-6, 0] #[1e-5, 1e-6, 0]\n",
    "encoded_space_dims = [10, 30]\n",
    "\n",
    "param_combinations = []\n",
    "for lr in learning_rates:\n",
    "    for opt in optimizers:\n",
    "        for wd in weight_decays:\n",
    "            for esd in encoded_space_dims:\n",
    "                param_combinations.append([lr, opt, wd, esd])\n",
    "print(f\"Number of combinations = {len(param_combinations)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if perform_grid_search:\n",
    "    ## GRID SEARCH TRAINING\n",
    "    _, _, val_losses = train_loop(param_combinations, k_folds=k_folds, num_epochs=num_epochs, train_dataset=train_dataset, device=device)\n",
    "    #find the index of the best combination\n",
    "    best_comb_index = np.argmin(val_losses)\n",
    "    best_comb = param_combinations[best_comb_index]\n",
    "    print(f\"Best combination: {best_comb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10-dimensional encoded space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get model accuracy\n",
    "def get_accuracy(encoder, dataset, single_layer=None):\n",
    "    this_dataloader = DataLoader(dataset, batch_size=20000)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for (data, label) in tqdm(this_dataloader):\n",
    "            data, label = data.to(device), label.to(device)\n",
    "            # Compute the output\n",
    "            output = encoder(data)\n",
    "            if single_layer is not None:\n",
    "                output = single_layer(output)\n",
    "            # Get the index of the max log-probability\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            # Add to the total number of correct predictions\n",
    "            correct += pred.eq(label.view_as(pred)).sum() #.item()\n",
    "            # Add to the total number of predictions\n",
    "            total += data.shape[0]\n",
    "    return correct/total\n",
    "\n",
    "### Test on examples\n",
    "def test_on_example(n_example, encoder, decoder, title, save_name=None, test_dataset=test_dataset):\n",
    "    # Get the output of a specific image (the test image at index 0 in this case)\n",
    "    img = test_dataset[n_example][0].unsqueeze(0).to(device)\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    with torch.no_grad():\n",
    "        rec_img  = decoder(encoder(img))\n",
    "    # Plot the reconstructed image\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(6,3))\n",
    "    axs[0].imshow(img.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "    axs[0].set_title('Original image')\n",
    "    axs[1].imshow(rec_img.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "    axs[1].set_title('Reconstructed image')\n",
    "    plt.tight_layout()\n",
    "    axs[0].axis('off')\n",
    "    axs[1].axis('off')\n",
    "    plt.pause(0.1)\n",
    "    plt.show()\n",
    "    if save_name is None:\n",
    "        save_name = title\n",
    "    fig.savefig(f\"images/{save_name}.png\", dpi=1000, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "#function to find good inputs, where the net is confident\n",
    "def find_good_inputs(encoder10, test_dataset, device):\n",
    "    # find an input for each class for which the encoder10 is very confident\n",
    "    fig, axs = plt.subplots(1, 10, figsize=(15,6))\n",
    "    inputs = []\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "    encoder10.eval()\n",
    "    for i in range(10):\n",
    "        found = False\n",
    "        for (image, label) in test_dataloader:\n",
    "            if label == i:\n",
    "                image, label = image.to(device), label.to(device)\n",
    "                output = encoder10(image)\n",
    "                output = torch.softmax(output, dim=1)\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                confidence = output.detach().cpu().numpy()[0][i]\n",
    "                # check if the prediction is correct\n",
    "                if pred == label and confidence > 0.95:\n",
    "                    print(f\"{label_names[i]} - confidence: {confidence}\")\n",
    "                    inputs.append(image)\n",
    "                    # plot image\n",
    "                    axs[i].imshow(image.squeeze().detach().cpu().numpy(), cmap='gray')\n",
    "                    found = True\n",
    "                    break\n",
    "        if not found:\n",
    "            print(f\"{label_names[i]} not found\")\n",
    "    plt.show()\n",
    "    return inputs\n",
    "\n",
    "def find_inputs(test_dataset):\n",
    "    inputs = []\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "    for i in range(10):\n",
    "        found = False\n",
    "        for (image, label) in test_dataloader:\n",
    "            if label == i:\n",
    "                inputs.append(image)\n",
    "                found = True\n",
    "                break\n",
    "        if not found:\n",
    "            print(f\"{label_names[i]} not found\")\n",
    "    return inputs\n",
    "                \n",
    "\n",
    "#train function\n",
    "def train(enc, dec, epochs, train_dataset, test_dataset, loss_fn, optim, device, apply_softmax=False):\n",
    "    # Define the dataloader\n",
    "    train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=True)\n",
    "    # Define the lists to store the losses\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    enc, dec = enc.to(device), dec.to(device)\n",
    "    enc.train()\n",
    "    dec.train()\n",
    "    # Train the model\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # Train the model\n",
    "        train_loss = train_epoch(enc, dec, device, train_loader, loss_fn, optim, apply_softmax=apply_softmax)\n",
    "        # Validate the model\n",
    "        test_loss = validate_epoch(enc, dec, device, test_loader, loss_fn, apply_softmax=apply_softmax)\n",
    "        # Add the loss to the list\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "    return enc, dec, train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "num_epochs10 = 150 #100 ~ 20 min\n",
    "encoded_space_dim = 10\n",
    "encoder10, decoder10 = Encoder(encoded_space_dim), Decoder(encoded_space_dim)\n",
    "optim10 = torch.optim.Adam(list(encoder10.parameters()) + list(decoder10.parameters()), lr=1e-3, weight_decay=0.0)\n",
    "#nn.MSELoss()\n",
    "loss_fn10 = nn.MSELoss()\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute the training loop\n",
    "\n",
    "if not load_good_model: #train from scratch\n",
    "    encoder10, decoder10, train_losses, test_losses = train(encoder10, decoder10, num_epochs10, train_dataset, test_dataset, loss_fn10, optim10, device, apply_softmax=False)\n",
    "    # save model\n",
    "    torch.save(encoder10.state_dict(), f\"good_models/encoder10_final_{num_epochs10}.pt\")\n",
    "    torch.save(decoder10.state_dict(), f\"good_models/decoder10_final_{num_epochs10}.pt\")\n",
    "    # save losses\n",
    "    with open(f\"good_models/losses10_{num_epochs10}.pkl\", 'wb') as f:\n",
    "        pickle.dump([train_losses, test_losses], f)\n",
    "else: #load pretrained model\n",
    "    encoder10.load_state_dict(torch.load(f\"good_models/encoder10_final_{num_epochs10}.pt\"))\n",
    "    decoder10.load_state_dict(torch.load(f\"good_models/decoder10_final_{num_epochs10}.pt\"))\n",
    "    print(\"Loaded pretrained model\")\n",
    "    #load losses\n",
    "    with open(f\"good_models/losses10_{num_epochs10}.pkl\", 'rb') as f:\n",
    "        train_losses, test_losses = pickle.load(f)\n",
    "\n",
    "#plot losses\n",
    "plot_losses(train_losses, test_losses, title=\"Losses for 10D Encoder and Decoder\", save_name=f\"losses10_{num_epochs10}\", label2=\"Test loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Test the model\n",
    "# calculate loss on training set\n",
    "encoder10, decoder10 = encoder10.to(device), decoder10.to(device)\n",
    "train_loss = validate_epoch(encoder10, decoder10, device, DataLoader(train_dataset, batch_size=60000), nn.MSELoss())\n",
    "print(f\"Train loss: {train_loss}\")\n",
    "# calculate loss on test set\n",
    "test_loss = validate_epoch(encoder10, decoder10, device, DataLoader(test_dataset, batch_size=20000), nn.MSELoss())\n",
    "print(f\"Test loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(18,22):\n",
    "    test_on_example(i, encoder10, decoder10, title=\"Test on example 10D-ESD\", save_name=f\"10D_reconstruction_example_{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-D Supervised fine tuning and comparison with supervised methods\n",
    "- 1 pt: fine-tune the (convolutional) autoencoder using a supervised classification task, and compare\n",
    "classification accuracy and learning speed with results achieved in Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder outputs for different classes before tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = find_good_inputs(encoder10, test_dataset, device)\n",
    "inputs = find_inputs(test_dataset)\n",
    "encoder10 = encoder10.to(device)\n",
    "encoder10.eval()\n",
    "outputs = []\n",
    "with torch.no_grad():\n",
    "    for i in inputs:\n",
    "        i = i.to(device)\n",
    "        out = encoder10(i)\n",
    "        out = F.softmax(out, dim=1)\n",
    "        outputs.append(out.cpu().numpy())\n",
    "\n",
    "#plot outputs\n",
    "fig1, axs = plt.subplots(10, 1, figsize=(12, 10))\n",
    "for i in range(10):\n",
    "    out = outputs[i][0]\n",
    "    # plot historgrams \n",
    "    axs[i].bar(range(10), out)\n",
    "    axs[i].set_title(f\"Encoder outputs for input {label_names[i]}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#save fig\n",
    "fig1.savefig(f\"images/encoder10_outputs_not_tuned_{num_epochs10}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fine tune the encoder10, the idea is to create a set of weights from the hidden representation to the output target encoded as a 10-vector (one-hot encoding vector of the class, like class 3 => [0001000000])). The idea for training is divided in steps:\n",
    "- step 1: fix the encoder2/encoder10 weights and train only the new layer\n",
    "- step 2: for a specified number of epochs repeat:\n",
    "    - fix encoder10 and train encoder10 using nn.CrossEntropyLoss() wrt the target\n",
    "    - fix encoder10 and train encoder10 using nn.MSELoss() wrt to the initial image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## step 1: single layer NN training\n",
    "# create the single layer NN to match the encoded_space_dim to the 10-dim one-encoded vector\n",
    "class SingleLayerNN(nn.Module):\n",
    "    def __init__(self, encoded_space_dim):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(encoded_space_dim, 10)\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "slm10 = SingleLayerNN(encoded_space_dim) #slm10 = single layer matcher\n",
    "\n",
    "# step 1: single layer NN training\n",
    "torch.manual_seed(0)\n",
    "#params\n",
    "single_layer_num_epochs = 10\n",
    "# dataloader\n",
    "slm_train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "#loss\n",
    "sl_loss_fn = nn.CrossEntropyLoss()\n",
    "#optimizer\n",
    "sl_optimizer = torch.optim.Adam(slm10.parameters(), lr=1e-3)\n",
    "# to gpu\n",
    "slm10.to(device)\n",
    "\n",
    "if not load_good_model:\n",
    "    #train loop\n",
    "    for epoch in tqdm(range(single_layer_num_epochs)):\n",
    "        #print(f\"Epoch {epoch+1}/{single_layer_num_epochs}\")\n",
    "        slm10.train()\n",
    "        epoch_loss = []\n",
    "        for (data, label) in slm_train_dataloader:\n",
    "            # target = onehot encoding of label\n",
    "            target = torch.eye(10)[label] \n",
    "            # Move the input and target data to the selected device\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # use pretrained encoder2 to encode the data\n",
    "            encoded_data = encoder10(data)\n",
    "            # Zero the gradients\n",
    "            sl_optimizer.zero_grad()\n",
    "            # Compute the output\n",
    "            output = slm10(encoded_data)\n",
    "            assert output.shape == target.shape\n",
    "            # Compute the loss\n",
    "            loss = sl_loss_fn(output, target)\n",
    "            # Compute the gradients\n",
    "            loss.backward()\n",
    "            # Update the weights\n",
    "            sl_optimizer.step()\n",
    "            #batch loss\n",
    "            loss_batch = loss.item()\n",
    "            epoch_loss.append(loss_batch)\n",
    "        # Return the average training loss\n",
    "        epoch_loss = np.mean(epoch_loss)\n",
    "        #print(f\"epoch loss: {epoch_loss}\")\n",
    "\n",
    "    step_1_train_accuracy = get_accuracy(encoder10, train_dataset, single_layer=slm10)\n",
    "    step_1_test_accuracy = get_accuracy(encoder10, test_dataset, single_layer=slm10)\n",
    "    #print train and test accuracy with 3 decimal places\n",
    "    print(f\"Train Accuracy WITHOUT Decoder tuning: {round(step_1_train_accuracy.item()*100, 1)} %\")\n",
    "    print(f\"Test Accuracy WITHOUT Decoder tuning: {round(step_1_test_accuracy.item()*100, 1)} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## STEP 2: Fine tuning\n",
    "torch.manual_seed(42)\n",
    "# this value decides how much the training will focus on correctly predicting labels vs reconstruncting the inputs\n",
    "mse_multiplier = 5 #8 \n",
    "step2_num_epochs = 150 #120 ~ 25 min\n",
    "target_losses, reconstruction_losses = [], []\n",
    "\n",
    "#load model\n",
    "if load_good_model:\n",
    "    decoder10.load_state_dict(torch.load(f'good_models/decoder10_finetuned_{step2_num_epochs}.pt'))\n",
    "    encoder10.load_state_dict(torch.load(f'good_models/encoder10_finetuned_{step2_num_epochs}.pt'))\n",
    "    slm10.load_state_dict(torch.load(f'good_models/slm10_finetuned_{step2_num_epochs}.pt'))\n",
    "    print(\"Loaded pretrained models\")\n",
    "    #load losses\n",
    "    with open(f\"good_models/losses10_finetuned_{step2_num_epochs}.pkl\", 'rb') as f:\n",
    "        target_losses, reconstruction_losses = pickle.load(f)\n",
    "else:\n",
    "    # dataloader\n",
    "    train_dataloader_2 = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "    #loss\n",
    "    loss_fn_2 = nn.CrossEntropyLoss()\n",
    "    dec_loss_fn = nn.MSELoss()\n",
    "    #optimizer\n",
    "    params_to_optimize = [\n",
    "                {'params': encoder10.parameters()},\n",
    "                {'params': decoder10.parameters()},\n",
    "                {'params': slm10.parameters()}\n",
    "            ]\n",
    "    optimizer_2 = torch.optim.Adam(params_to_optimize, lr=1e-3, weight_decay=1e-5)\n",
    "    # to gpu\n",
    "    encoder10.to(device)\n",
    "    decoder10.to(device)\n",
    "\n",
    "    #train loop\n",
    "    target_losses = []\n",
    "    reconstruction_losses = []\n",
    "    for epoch in tqdm(range(step2_num_epochs)):\n",
    "        #print(f\"Epoch {epoch+1}/{step2_num_epochs}\")\n",
    "        encoder10.train()\n",
    "        decoder10.train()\n",
    "        epoch_losses2 = []\n",
    "        dec_losses = []\n",
    "        for (data, label) in train_dataloader_2:\n",
    "            # Zero the gradients\n",
    "            optimizer_2.zero_grad()\n",
    "            ## ENCODER TRAINING + SINGLE LAYER MATCHER TRAINING\n",
    "            # target = onehot encoding of label\n",
    "            target = torch.eye(10)[label] \n",
    "            # Move the input and target data to the selected device\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # use pretrained encoder to encode the data\n",
    "            encoded_data = encoder10(data)\n",
    "            # Compute the output\n",
    "            slm_out = slm10(encoded_data)\n",
    "            assert slm_out.shape == target.shape\n",
    "            # Compute the loss\n",
    "            loss2 = loss_fn_2(slm_out, target) #cross entropy loss\n",
    "            # Compute the gradients\n",
    "            loss2.backward(retain_graph=True)\n",
    "            ## DECODER TRAINING\n",
    "            # Compute the output\n",
    "            decoded_data = decoder10(encoded_data)\n",
    "            # Compute the loss\n",
    "            dec_loss = mse_multiplier*dec_loss_fn(decoded_data, data) # for more weightage\n",
    "            # Compute the gradients\n",
    "            dec_loss.backward()\n",
    "\n",
    "            # Update the weights\n",
    "            optimizer_2.step()\n",
    "\n",
    "            #batch loss\n",
    "            loss_batch2 = loss2.item()\n",
    "            epoch_losses2.append(loss_batch2)\n",
    "            dec_loss_batch = dec_loss.item()\n",
    "            dec_losses.append(dec_loss_batch)\n",
    "\n",
    "        # Return the average training loss\n",
    "        epoch_loss2 = np.mean(epoch_losses2)\n",
    "        #print(f\"target loss: {epoch_loss2}\")\n",
    "        target_losses.append(epoch_loss2)\n",
    "        dec_loss = np.mean(dec_losses)\n",
    "        #print(f\"reconstruction loss (x{mse_multiplier}): {dec_loss}\")\n",
    "        reconstruction_losses.append(dec_loss)\n",
    "    \n",
    "    torch.save(decoder10.state_dict(), f'good_models/decoder10_finetuned_{step2_num_epochs}.pt')\n",
    "    torch.save(encoder10.state_dict(), f'good_models/encoder10_finetuned_{step2_num_epochs}.pt')\n",
    "    torch.save(slm10.state_dict(), f'good_models/slm10_finetuned_{step2_num_epochs}.pt')\n",
    "    #save losses\n",
    "    with open(f\"good_models/losses10_finetuned_{step2_num_epochs}.pkl\", 'wb') as f:\n",
    "        pickle.dump((target_losses, reconstruction_losses), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot losses\n",
    "plot_losses(target_losses, reconstruction_losses, \n",
    "                title=\"Target and Reconstruction Losses 10-D Finetuning\", save_name=f\"losses_encoder10_finetuned_{step2_num_epochs}\",\n",
    "                label1=\"Target loss\",label2=\"Reconstruction loss\",max_y=1.5)\n",
    "#accuracy\n",
    "step_2_train_accuracy = get_accuracy(encoder10, train_dataset, single_layer=slm10)\n",
    "step_2_test_accuracy = get_accuracy(encoder10, test_dataset, single_layer=slm10)\n",
    "#print train and test accuracy with 3 decimal places\n",
    "print(f\"Train Accuracy After Decoder Tuning: {round(step_2_train_accuracy.item()*100, 1)} %\")\n",
    "print(f\"Test Accuracy After Decoder Tuning: {round(step_2_test_accuracy.item()*100, 1)} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test on examples\n",
    "for i in range(18,23):\n",
    "    test_on_example(i, encoder10, decoder10, title=\"Test after supervised fine tuning\", save_name=f\"10D_reconstruction_example_finetuned_{i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-D Latent space exploration and generation of new samples\n",
    "- 2 pt: explore the latent space structure (e.g., PCA, t-SNE) and generate new samples from latent codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder outputs for different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = find_good_inputs(encoder10, test_dataset, device)\n",
    "inputs = find_inputs(test_dataset)\n",
    "encoder10 = encoder10.to(device)\n",
    "encoder10.eval()\n",
    "outputs = []\n",
    "with torch.no_grad():\n",
    "    for i in inputs:\n",
    "        i = i.to(device)\n",
    "        out = encoder10(i)\n",
    "        out = torch.softmax(out, dim=1)\n",
    "        outputs.append(out.cpu().numpy())\n",
    "\n",
    "#plot outputs\n",
    "fig2, axs = plt.subplots(10, 1, figsize=(12, 10))\n",
    "for i in range(10):\n",
    "    out = outputs[i][0]\n",
    "    # plot historgrams \n",
    "    axs[i].bar(range(10), out)\n",
    "    axs[i].set_title(f\"Encoder outputs for input {label_names[i]}\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#save fig\n",
    "fig2.savefig(f\"images/encoder10_outputs_finetuned_{step2_num_epochs}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some bold statements from the encoder here, apparently a boot is a sneaker, hard to blame though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get the encoded representation of the test samples\n",
    "encoded_samples = []\n",
    "for sample in tqdm(test_dataset):\n",
    "    img = sample[0].unsqueeze(0).to(device)\n",
    "    label = sample[1]\n",
    "    # Encode image\n",
    "    encoder10.eval()\n",
    "    with torch.no_grad():\n",
    "        encoded_img  = encoder10(img)\n",
    "    # Append to list\n",
    "    encoded_img = encoded_img.flatten().cpu().numpy()\n",
    "    encoded_sample = {f\"Enc. Variable {i}\": enc for i, enc in enumerate(encoded_img)}\n",
    "    encoded_sample['label'] = label\n",
    "    encoded_samples.append(encoded_sample)\n",
    "\n",
    "encoded_samples = pd.DataFrame(encoded_samples)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "encoded_samples_reduced_PCA = pca.fit_transform(encoded_samples)\n",
    "import plotly.express as px\n",
    "fig2a = px.scatter(encoded_samples_reduced_PCA, x=0, y =1, \n",
    "    color=[label_names[l] for l in encoded_samples.label.to_numpy()], opacity=0.7)\n",
    "fig2a.show()\n",
    "#save figure as eps\n",
    "fig2a.write_image(f'images/10D_finetuned_PCA.eps', width=2000, height=700)\n",
    "\n",
    "# very interesting but computationally expensive\n",
    "# pca3 = PCA(n_components=3)\n",
    "# encoded_samples_reduced_PCA3 = pca3.fit_transform(encoded_samples)\n",
    "# fig2b = px.scatter_3d(encoded_samples_reduced_PCA3, x=0, y=1, z=2, \n",
    "#     color=[label_names[l] for l in encoded_samples.label.to_numpy()], opacity=0.7)\n",
    "# fig2b.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "le6_nLs7j7jq"
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "encoded_samples_reduced_TSNE = tsne.fit_transform(encoded_samples)\n",
    "fig3a = px.scatter(encoded_samples_reduced_TSNE, x=0, y =1, \n",
    "    color=[label_names[l] for l in encoded_samples.label.to_numpy()], opacity=0.7)\n",
    "fig3a.show()\n",
    "fig3a.write_image(f'images/10D_finetuned_TSNE.eps', width=2000, height=700)\n",
    "\n",
    "# very interesting but computationally expensive\n",
    "# tsne3 = TSNE(n_components=3)\n",
    "# encoded_samples_reduced_TSNE3 = tsne3.fit_transform(encoded_samples)\n",
    "# fig3b = px.scatter_3d(encoded_samples_reduced_TSNE3, x=0, y=1, z=2,\n",
    "#     color=[label_names[l] for l in encoded_samples.label.to_numpy()], opacity=0.7)\n",
    "# fig3b.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New samples generation\n",
    "To generate new samples the idea is to take all the examples for which the classification is confident and correct, then calculate the encodint for these examples and find the mean and std of the encodings for each class, to have an approxximation of the average good encoding. To generate samples we start from the avg and we inject noise using the std."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "good_encodings = [[] for _ in range(10)]\n",
    "with torch.no_grad():\n",
    "    encoder10.eval()\n",
    "    for imgs, labels in DataLoader(test_dataset, batch_size=len(test_dataset)):\n",
    "        imgs = imgs.to(device)\n",
    "        encoded_imgs = encoder10(imgs)\n",
    "        class_outs = torch.softmax(slm10(encoded_imgs), dim=1)\n",
    "        class_outs = class_outs.cpu().numpy()\n",
    "        encoded_images = encoded_imgs.cpu().numpy()\n",
    "        out_labels = np.argmax(class_outs, axis=1)\n",
    "        for (out_label, label, class_out, enc_img) in zip(out_labels, labels, class_outs, encoded_images):\n",
    "            if out_label == label and class_out[label] > 0.95: #correct and confident prediction\n",
    "                good_encodings[label].append(enc_img)\n",
    "#find the average encoding for each class\n",
    "avg_encoding = []\n",
    "std_encoding = []\n",
    "for i in range(10):\n",
    "    if len(good_encodings[i]) > 0:\n",
    "        #average the encodings\n",
    "        avg_encoding.append(np.mean(good_encodings[i], axis=0))\n",
    "        #get standard deviation\n",
    "        std_encoding.append(np.std(good_encodings[i], axis=0))\n",
    "    else:\n",
    "        print(f\"No good encodings for class {i}\")\n",
    "        avg_encoding.append(np.zeros(encoded_imgs.shape[1]))\n",
    "        std_encoding.append(np.zeros(encoded_imgs.shape[1]))\n",
    "\n",
    "fig, axs = plt.subplots(10, 10, figsize=(12, 12))\n",
    "with torch.no_grad():\n",
    "    decoder10.eval()\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            encoded_img = torch.from_numpy(avg_encoding[i]).to(device)\n",
    "            std = torch.from_numpy(std_encoding[i]).to(device)\n",
    "            #add random noise to the encoding\n",
    "            encoded_img = encoded_img + 0.7 * torch.normal(mean=torch.zeros(encoded_img.shape, device=device), std=std)\n",
    "            generated_img = decoder10(encoded_img.unsqueeze(0)).squeeze(0).squeeze(0).cpu().numpy()\n",
    "            # generated_img = np.transpose(generated_img, (1, 2, 0))\n",
    "            axs[j][i].imshow(generated_img, cmap='gray')\n",
    "            axs[j][i].set_xticks([])\n",
    "            axs[j][i].set_yticks([])\n",
    "\n",
    "    \n",
    "#show fig\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "#save fig\n",
    "fig.savefig(f\"images/new_samples_generated_finetuned_10_{step2_num_epochs}.png\", dpi=500)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cee89b7c6bc96453738565335b56b694d8a30ac65e979633b683f8408c8233c6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('dl_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
