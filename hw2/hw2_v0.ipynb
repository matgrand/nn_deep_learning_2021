{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HOMEWORK 2 NEURAL NETWORKS AND DEEP LEARNING\n",
    "\n",
    "---\n",
    "A.A. 2021/22 (6 CFU) - Dr. Alberto Testolin, Dr. Umberto Michieli\n",
    "---\n",
    "Student: Matteo Grandin\n",
    "---\n",
    "id: 2020374"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General overview\n",
    " In this homework you will learn how to implement and test neural network models for\n",
    "solving unsupervised problems. For simplicity and to allow continuity with the kind of data you have seen\n",
    "before, the homework will be based on images of FashionMNIST. However, you can optionally explore\n",
    "different image collections (e.g., Caltech or Cifar) or other datasets based on your interests. The basic tasks\n",
    "for the homework will require to test and analyze the convolutional autoencoder implemented during the\n",
    "Lab practice. If you prefer, you can opt for a fully-connected autoencoder, which should achieve similar\n",
    "performance considering the relatively small size of the FashionMNIST images. As for the previous\n",
    "homework, you should explore the use of advanced optimizers and regularization methods. Learning\n",
    "hyperparameters should be tuned using appropriate search procedures, and final accuracy should be\n",
    "evaluated using a cross-validation setup. More advanced tasks will require the exploration of denoising and\n",
    "variational / adversarial architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional autoencoder\n",
    "- implement and test (convolutional) autoencoder, reporting the trend of reconstruction loss and\n",
    "some examples of image reconstruction; explore advanced optimizers and regularization methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # plotting library\n",
    "import numpy as np # this module is useful to work with numerical arrays\n",
    "import pandas as pd # this module is useful to work with tabular data\n",
    "import random # this module will be used to select random samples from a collection\n",
    "import os # this module will be used just to create directories in the local filesystem\n",
    "from tqdm import tqdm # this module is useful to plot progress bars\n",
    "from sklearn.model_selection import KFold # this module is useful to split data into training and test sets\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset\n",
    "# training and validation will be performed on the training dataset\n",
    "train_dataset = torchvision.datasets.FashionMNIST('data', train=True, download=True)\n",
    "# test dataset will only be used for evaluating final model performance\n",
    "test_dataset  = torchvision.datasets.FashionMNIST('data', train=False, download=True)\n",
    "\n",
    "label_names=['t-shirt','trouser','pullover','dress','coat','sandal','shirt',\n",
    "             'sneaker','bag','boot']\n",
    "num_labels = len(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data transformation\n",
    "train_transform = transforms.Compose([\n",
    "    # OneHotEncoder(num_classes=10),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    # OneHotEncoder(num_classes=10),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Set the train transform\n",
    "train_dataset.transform = train_transform\n",
    "# Set the test transform\n",
    "test_dataset.transform = test_transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model definition\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, encoded_space_dim):\n",
    "        super().__init__()\n",
    "        ### Convolutional section\n",
    "        self.encoder_cnn = nn.Sequential(\n",
    "            # First convolutional layer\n",
    "            nn.Conv2d(in_channels= 1, out_channels=8, kernel_size=3, \n",
    "                      stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            # Second convolutional layer\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, \n",
    "                      stride=2, padding=1),\n",
    "            nn.ReLU(True),\n",
    "            # Third convolutional layer\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, \n",
    "                      stride=2, padding=0),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        ### Flatten layer\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        ### Linear section\n",
    "        self.encoder_lin = nn.Sequential(\n",
    "            # First linear layer\n",
    "\n",
    "            nn.Linear(in_features=32*3*3, out_features=64),\n",
    "            nn.ReLU(True),\n",
    "            # Second linear layer\n",
    "            nn.Linear(in_features=64, out_features=encoded_space_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        # Apply convolutions\n",
    "        x = self.encoder_cnn(x)\n",
    "        # Flatten\n",
    "        x = self.flatten(x)\n",
    "        # # Apply linear layers\n",
    "        x = self.encoder_lin(x)\n",
    "        return x\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, encoded_space_dim):\n",
    "        super().__init__()\n",
    "        ### Linear section\n",
    "        self.decoder_lin = nn.Sequential(\n",
    "            # First linear layer\n",
    "            nn.Linear(in_features=encoded_space_dim, out_features=64),\n",
    "            nn.ReLU(True),\n",
    "            # Second linear layer\n",
    "            nn.Linear(in_features=64, out_features=3*3*32),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        ### Unflatten\n",
    "        self.unflatten = nn.Unflatten(dim=1, unflattened_size=(32, 3, 3))\n",
    "        ### Convolutional section\n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            # First transposed convolution\n",
    "            nn.ConvTranspose2d(in_channels=32, out_channels=16, kernel_size=3, \n",
    "                               stride=2, output_padding=0),\n",
    "            nn.ReLU(True),\n",
    "            # Second transposed convolution\n",
    "            nn.ConvTranspose2d(in_channels=16, out_channels=8, kernel_size=3, \n",
    "                               stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(True),\n",
    "            # Third transposed convolution\n",
    "            nn.ConvTranspose2d(in_channels=8, out_channels=1, kernel_size=3, \n",
    "                               stride=2, padding=1, output_padding=1)\n",
    "        ) \n",
    "    def forward(self, x):\n",
    "        # Apply linear layers\n",
    "        x = self.decoder_lin(x)\n",
    "        # Unflatten\n",
    "        x = self.unflatten(x)\n",
    "        # Apply transposed convolutions\n",
    "        x = self.decoder_conv(x)\n",
    "        # Apply a sigmoid to force the output to be between 0 and 1 (valid pixel values)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Training function\n",
    "def train_epoch(encoder, decoder, device, dataloader, loss_fn, optimizer):\n",
    "    # Set train mode for both the encoder and the decoder\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    train_loss = []\n",
    "    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n",
    "    for (image_batch, _) in dataloader: # with \"_\" we just ignore the labels (the second element of the dataloader tuple)\n",
    "        # Move tensor to the proper device\n",
    "        image_batch = image_batch.to(device)\n",
    "        # Encode data\n",
    "        encoded_data = encoder(image_batch)\n",
    "        # Decode data\n",
    "        decoded_data = decoder(encoded_data)\n",
    "        # Evaluate loss\n",
    "        loss = loss_fn(decoded_data, image_batch)\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Add loss to the list\n",
    "        train_loss.append(loss.data.detach().cpu().numpy())\n",
    "    train_loss = np.mean(train_loss)\n",
    "    #print(f\"Batch Train loss: {train_loss}\")\n",
    "    return train_loss\n",
    "\n",
    "### Testing function\n",
    "def validate_epoch(encoder, decoder, device, dataloader, loss_fn):\n",
    "    # Set evaluation mode for encoder and decoder\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    with torch.no_grad(): # No need to track the gradients\n",
    "        # Define the lists to store the outputs for each batch\n",
    "        conc_out = []\n",
    "        conc_label = []\n",
    "        for (image_batch, _) in dataloader:\n",
    "            # Move tensor to the proper device\n",
    "            image_batch = image_batch.to(device)\n",
    "            # Encode data\n",
    "            encoded_data = encoder(image_batch)\n",
    "            # Decode data\n",
    "            decoded_data = decoder(encoded_data)\n",
    "            # Append the network output and the original image to the lists\n",
    "            conc_out.append(decoded_data.cpu())\n",
    "            conc_label.append(image_batch.cpu())\n",
    "        # Create a single tensor with all the values in the lists\n",
    "        conc_out = torch.cat(conc_out)\n",
    "        conc_label = torch.cat(conc_label) \n",
    "        # Evaluate global loss\n",
    "        val_loss = loss_fn(conc_out, conc_label)\n",
    "        #print(f\"Batch Validation loss: {val_loss}\")\n",
    "    return val_loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#useful functions\n",
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(train_losses, label=\"Training loss\")\n",
    "    plt.plot(val_losses, label=\"Validation loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def reset_weights(model):\n",
    "    for layer in model.modules():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize hyperparameters\n",
    "- 1 pt: optimize hyperparameters using grid/random search or automatic tuning tools (e.g., Optuna)\n",
    "- final accuracy should be evaluated using a cross-validation setup (concatenate training and test set like in here, than evaluate accuracy for each fold and take the avg https://www.machinecurve.com/index.php/2021/02/03/how-to-use-k-fold-cross-validation-with-pytorch/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decide to load or not the pretrained model\n",
    "load_good_model = False\n",
    "\n",
    "#create a folder called training to save the model\n",
    "if not load_good_model:\n",
    "    if not os.path.exists('data/training'):\n",
    "        os.makedirs('data/training')\n",
    "    #clear the training folder\n",
    "    if os.listdir('data/training'):\n",
    "        for f in os.listdir('data/training'):\n",
    "            os.remove(os.path.join('data/training', f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "#create param combinations for grid search parameters tuning\n",
    "lr = 1e-3\n",
    "encoded_space_dim = 2\n",
    "param_combinations = [[lr, 0, 0, encoded_space_dim],[1e-2, 0,0, 2], [1e-3, 0, 0, 8], [1e-2, 0,0, 8]]\n",
    "print(len(param_combinations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: cuda\n",
      "Training set: Dataset FashionMNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: data\n",
      "    Split: Train\n",
      "*****************************************************************************\n",
      "Parameter combination 0: [0.001, 0, 0, 2]\n",
      "___________________________________________________\n",
      "Fold 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "### Main block\n",
    "k_folds = 5\n",
    "num_epochs = 50\n",
    "\n",
    "# Check if the GPU is available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Selected device: {device}')\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "print(f\"Training set: {train_dataset}\")\n",
    "\n",
    "for comb, params in enumerate(param_combinations):\n",
    "    print(\"*****************************************************************************\")\n",
    "    print(f\"Parameter combination {comb}: {params}\")\n",
    "    lr, par2, par3, encoded_space_dim = params\n",
    "    ## train the model\n",
    "    # perform cross validation \n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True)\n",
    "    #initialize trainining and validation losses\n",
    "    comb_train_losses = np.zeros(num_epochs)\n",
    "    comb_val_losses = np.zeros(num_epochs)\n",
    "    for fold, (train_ids, validation_ids) in enumerate(kfold.split(train_dataset)):\n",
    "        print(\"___________________________________________________\")\n",
    "        print(f\"Fold {fold}\")\n",
    "        # Sample elements randomly from a given list of ids, no replacement.\n",
    "        train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "        validation_subsampler = torch.utils.data.SubsetRandomSampler(validation_ids)\n",
    "        # dataloaders\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=256, sampler=train_subsampler) \n",
    "        validation_dataloader = DataLoader(train_dataset, batch_size=256, sampler=validation_subsampler) \n",
    "        # initialize models\n",
    "        enc = Encoder(encoded_space_dim)\n",
    "        dec = Decoder(encoded_space_dim)\n",
    "        #reset weights\n",
    "        enc.apply(reset_weights)\n",
    "        dec.apply(reset_weights)\n",
    "        # initialize optimizer\n",
    "        params_to_optimize = [\n",
    "            {'params': enc.parameters()},\n",
    "            {'params': dec.parameters()}\n",
    "        ]\n",
    "        optim = torch.optim.Adam(params_to_optimize, lr=lr, weight_decay=1e-5)\n",
    "        # initialize loss function\n",
    "        loss_fn = nn.MSELoss()\n",
    "        # move to device\n",
    "        enc.to(device)\n",
    "        dec.to(device)\n",
    "        # train the model\n",
    "        i_train_losses = []\n",
    "        i_val_losses = []\n",
    "        for epoch in tqdm(range(num_epochs)):\n",
    "            #print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "            #train\n",
    "            epoch_train_loss = train_epoch(enc, dec, device, train_dataloader, loss_fn, optim)\n",
    "            #validate\n",
    "            epoch_val_loss = validate_epoch(enc, dec, device, validation_dataloader, loss_fn)\n",
    "            # store losses\n",
    "            i_train_losses.append(epoch_train_loss)\n",
    "            i_val_losses.append(epoch_val_loss)\n",
    "            # save model\n",
    "            torch.save(enc.state_dict(), f\"data/training/encoder_{comb}_{fold}_{epoch}.pt\")\n",
    "            torch.save(dec.state_dict(), f\"data/training/decoder_{comb}_{fold}_{epoch}.pt\")\n",
    "        \n",
    "        comb_train_losses += np.array(i_train_losses)/k_folds\n",
    "        comb_val_losses += np.array(i_val_losses)/k_folds\n",
    "    \n",
    "    plot_losses(comb_train_losses, comb_val_losses)\n",
    "\n",
    "    # train and validation loss for paramters combination\n",
    "    comb_train_loss = comb_train_losses[-1] # last epoch\n",
    "    comb_val_loss = comb_val_losses[-1] # last epoch\n",
    "    print(f\"\\n\\n\\nCombination {comb} Train loss: {comb_train_loss}\")\n",
    "    print(f\"Combination {comb} Validation loss: {comb_val_loss}\")\n",
    "\n",
    "# save losses\n",
    "with open(f\"data/training/losses_{comb}.pkl\", 'wb') as f:\n",
    "    pickle.dump([train_losses, val_losses], f)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised fine tuning and comparison with supervised methods\n",
    "- 1 pt: fine-tune the (convolutional) autoencoder using a supervised classification task, and compare\n",
    "classification accuracy and learning speed with results achieved in Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent space exploration and generation of new samples\n",
    "- 2 pt: explore the latent space structure (e.g., PCA, t-SNE) and generate new samples from latent codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational autoencoder / GAN / SimCLR\n",
    "- 2 pt: implement and test variational (convolutional) autoencoder or GAN or SimCLR"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cee89b7c6bc96453738565335b56b694d8a30ac65e979633b683f8408c8233c6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('dl_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
