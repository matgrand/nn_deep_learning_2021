{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Network\n",
    "- 2 pt: implement and test variational (convolutional) autoencoder or GAN or SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "#create the folder images/gan if it does not exist\n",
    "import os\n",
    "if not os.path.exists('images/gan'):\n",
    "    os.makedirs('images/gan')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.style.use('ggplot')\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# learning parameters\n",
    "batch_size = 256\n",
    "epochs = 800 # 800 but maybe even more is better\n",
    "sample_size = 64 # fixed sample size\n",
    "nz = 128 # latent vector size\n",
    "k = 1 # number of steps to apply to the netD\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,),(0.5,)), #this is very important\n",
    "])\n",
    "\n",
    "to_pil_image = transforms.ToPILImage()\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netG(\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=256, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Linear(in_features=256, out_features=512, bias=True)\n",
      "    (3): LeakyReLU(negative_slope=0.2)\n",
      "    (4): Linear(in_features=512, out_features=1024, bias=True)\n",
      "    (5): LeakyReLU(negative_slope=0.2)\n",
      "    (6): Linear(in_features=1024, out_features=784, bias=True)\n",
      "    (7): Tanh()\n",
      "  )\n",
      ")\n",
      "netD(\n",
      "  (main): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=1024, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Dropout(p=0.3, inplace=False)\n",
      "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2)\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (7): LeakyReLU(negative_slope=0.2)\n",
      "    (8): Dropout(p=0.3, inplace=False)\n",
      "    (9): Linear(in_features=256, out_features=1, bias=True)\n",
      "    (10): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class netG(nn.Module):\n",
    "    def __init__(self, nz):\n",
    "        super(netG, self).__init__()\n",
    "        self.nz = nz\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(self.nz, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x).view(-1, 1, 28, 28)\n",
    "\n",
    "class netD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(netD, self).__init__()\n",
    "        self.n_input = 784\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(self.n_input, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        return self.main(x)\n",
    "\n",
    "netG = netG(nz).to(device)\n",
    "netD = netD().to(device)\n",
    "\n",
    "print(netG)\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizers\n",
    "optim_g = optim.Adam(netG.parameters(), lr=0.0002)\n",
    "optim_d = optim.Adam(netD.parameters(), lr=0.0002)\n",
    "\n",
    "# loss function\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "losses_g = [] # to store netG loss after each epoch\n",
    "losses_d = [] # to store netD loss after each epoch\n",
    "images = [] # to store images generatd by the netG\n",
    "\n",
    "# to create real labels (1s)\n",
    "def label_real(size):\n",
    "    data = torch.ones(size, 1)\n",
    "    return data.to(device)\n",
    "\n",
    "# to create fake labels (0s)\n",
    "def label_fake(size):\n",
    "    data = torch.zeros(size, 1)\n",
    "    return data.to(device)\n",
    "\n",
    "# function to create the noise vector\n",
    "def create_noise(sample_size, nz):\n",
    "    return torch.randn(sample_size, nz).to(device)\n",
    "\n",
    "# to save the images generated by the netG\n",
    "def save_generator_image(image_batch, path):\n",
    "    save_image(image_batch, path)\n",
    "\n",
    "# function to train the netD network\n",
    "def train_discriminator(optimizer, real_image_batch, fake_image_batch):\n",
    "    b_size = real_image_batch.size(0)\n",
    "    real_label = label_real(b_size)\n",
    "    fake_label = label_fake(b_size)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    output_real = netD(real_image_batch)\n",
    "    loss_real = loss_fn(output_real, real_label)\n",
    "\n",
    "    output_fake = netD(fake_image_batch)\n",
    "    loss_fake = loss_fn(output_fake, fake_label)\n",
    "\n",
    "    loss_real.backward()\n",
    "    loss_fake.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss_real + loss_fake\n",
    "\n",
    "# function to train the netG network\n",
    "def train_generator(optimizer, fake_image_batch):\n",
    "    b_size = fake_image_batch.size(0)\n",
    "    real_label = label_real(b_size)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    output = netD(fake_image_batch)\n",
    "    loss = loss_fn(output, real_label)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'good_models/GAN_generator_1200.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5311/2323270455.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mnetG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'good_models/GAN_generator_{epochs}.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mnetD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'good_models/GAN_discriminator_{epochs}.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;31m#load losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/nn_deep_learning_2021/dl_env/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'good_models/GAN_generator_1200.pth'"
     ]
    }
   ],
   "source": [
    "## Training\n",
    "load_good_GAN = True\n",
    "\n",
    "if not load_good_GAN: # RETRAIN THE GAN\n",
    "\n",
    "    # create the noise vector\n",
    "    noise = create_noise(sample_size, nz)\n",
    "\n",
    "    netG.train()\n",
    "    netD.train()\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        #print(f\"Epoch {epoch} of {epochs}\")\n",
    "        loss_g = 0.0\n",
    "        loss_d = 0.0\n",
    "        for bi, data in enumerate(train_dataloader):\n",
    "            image_batch, _ = data\n",
    "            image_batch = image_batch.to(device)\n",
    "            b_size = len(image_batch)\n",
    "            # run the netD for k number of steps\n",
    "            for step in range(k):\n",
    "                fake_image_batch = netG(create_noise(b_size, nz)).detach()\n",
    "                real_image_batch = image_batch\n",
    "                # train the netD network\n",
    "                loss_d += train_discriminator(optim_d, real_image_batch, fake_image_batch)\n",
    "            fake_image_batch = netG(create_noise(b_size, nz))\n",
    "            # train the netG network\n",
    "            loss_g += train_generator(optim_g, fake_image_batch)\n",
    "\n",
    "        # create the final fake image_batch for the epoch\n",
    "        generated_img = netG(noise).cpu().detach()\n",
    "        # make the images as grid\n",
    "        generated_img = make_grid(generated_img)\n",
    "        # save the generated torch tensor models to disk\n",
    "        save_generator_image(generated_img, f\"data/training/gen_img{epoch}.png\")\n",
    "        images.append(generated_img)\n",
    "        epoch_loss_g = loss_g / bi # total netG loss for the epoch\n",
    "        epoch_loss_d = loss_d / bi # total netD loss for the epoch\n",
    "        losses_g.append(epoch_loss_g)\n",
    "        losses_d.append(epoch_loss_d)\n",
    "        #print(f\"netG loss: {epoch_loss_g:.8f}, netD loss: {epoch_loss_d:.8f}\")\n",
    "\n",
    "    print('DONE TRAINING')\n",
    "    torch.save(netG.state_dict(), f'good_models/GAN_generator_{epochs}.pth')\n",
    "    torch.save(netD.state_dict(), f'good_models/GAN_discriminator_{epochs}.pth')\n",
    "    #save losses\n",
    "    with open(f'data/training/losses_g_{epochs}.pkl', 'wb') as f:\n",
    "        pickle.dump(losses_g, f)\n",
    "    with open(f'data/training/losses_d_{epochs}.pkl', 'wb') as f:\n",
    "        pickle.dump(losses_d, f)\n",
    "\n",
    "else:\n",
    "    netG.load_state_dict(torch.load(f'good_models/GAN_generator_{epochs}.pth'))\n",
    "    netD.load_state_dict(torch.load(f'good_models/GAN_discriminator_{epochs}.pth'))\n",
    "    #load losses\n",
    "    with open(f'data/training/losses_g_{epochs}.pkl', 'rb') as f:\n",
    "        losses_g = pickle.load(f)\n",
    "    with open(f'data/training/losses_d_{epochs}.pkl', 'rb') as f:\n",
    "        losses_d = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the generated images as GIF file\n",
    "imgs = [np.array(to_pil_image(img)) for img in images]\n",
    "imageio.mimsave('images/gan/generator_images.gif', imgs)\n",
    "\n",
    "# plot and save the netG and netD loss\n",
    "plt.figure()\n",
    "plt.plot(losses_g, label='netG loss')\n",
    "plt.plot(losses_d, label='netD Loss')\n",
    "plt.legend()\n",
    "plt.savefig('images/gan/losses.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## real vs fake\n",
    "# Grab a batch of real images from the dataloader\n",
    "real_batch = next(iter(train_dataloader))\n",
    "\n",
    "# Plot the real images\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(torchvision.utils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "# Plot the fake images from the last epoch\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(images[-1],(1,2,0)))\n",
    "plt.show()\n",
    "\n",
    "# save the generated images\n",
    "fig.savefig('images/gan/gan_real_vs_fake_images.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "#%%capture\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in images]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd69f43f58546b570e94fd7eba7b65e6bcc7a5bbc4eab0408017d18902915d69"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
