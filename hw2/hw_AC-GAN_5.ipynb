{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Network\n",
    "- 2 pt: implement and test variational (convolutional) autoencoder or GAN or SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import imageio\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "#create the folder images/gan if it does not exist\n",
    "import os\n",
    "if not os.path.exists('images/gan'):\n",
    "    os.makedirs('images/gan')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu') #for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.style.use('ggplot')\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# learning parameters\n",
    "batch_size = 256\n",
    "epochs = 400 # 800 but maybe even more is better, 20 ~ 5 min\n",
    "sample_size = 64 # fixed sample size\n",
    "nz = 128 # latent vector size\n",
    "k = 1 # number of steps to apply to the netD\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,),(0.5,)), #this is very important\n",
    "])\n",
    "\n",
    "to_pil_image = transforms.ToPILImage()\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class netG(nn.Module):\n",
    "    def __init__(self, nz):\n",
    "        super(netG, self).__init__()\n",
    "        self.nz = nz\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(self.nz, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.main(x).view(-1, 1, 28, 28) #unflatten the image\n",
    "\n",
    "class netD(nn.Module):\n",
    "    def __init__(self, out_dim):\n",
    "        super(netD, self).__init__()\n",
    "        self.n_input = 784\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(self.n_input, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(256, out_dim),\n",
    "            #nn.Sigmoid(), # sigmoid will be applied before loss only in the last output\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784) #flatten the image\n",
    "        return self.main(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create real labels (1s)\n",
    "def label_real(size):\n",
    "    data = torch.ones(size, 1)\n",
    "    return data.to(device)\n",
    "\n",
    "# to create fake labels (0s)\n",
    "def label_fake(size):\n",
    "    data = torch.zeros(size, 1)\n",
    "    return data.to(device)\n",
    "\n",
    "# function to create the noise vector\n",
    "def create_noise(sample_size, nz):\n",
    "    return torch.randn(sample_size, nz).to(device)\n",
    "\n",
    "# to save the images generated by the netG\n",
    "def save_generator_image(image_batch, path):\n",
    "    save_image(image_batch, path)\n",
    "\n",
    "# function to train the netD network\n",
    "def train_discriminator(optimizer, real_image_batch, fake_image_batch, loss_fn, netD, targets, class_loss_fn=nn.CrossEntropyLoss()):\n",
    "    b_size = real_image_batch.size(0)\n",
    "    real_label = label_real(b_size)\n",
    "    fake_label = label_fake(b_size)\n",
    "\n",
    "    # print(f\"real_label shape: {real_label.shape}\")\n",
    "    # print(f\"targets shape: {targets.shape}\")\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    output_real = netD(real_image_batch)\n",
    "    #divide the output in target and true/fake label\n",
    "    output_real_target = output_real[:, :10]\n",
    "    output_real_label = output_real[:, 10:]\n",
    "    # apply sigmopid \n",
    "    output_real_label = torch.sigmoid(output_real_label)\n",
    "\n",
    "    # assert output_real_target.shape == targets.shape , f\"output_real_target shape: {output_real_target.shape} and targets shape: {targets.shape}\"\n",
    "    # assert output_real_label.shape == real_label.shape, f\"output_real_label shape: {output_real_label.shape} and real_label shape: {real_label.shape}\"\n",
    "\n",
    "    loss_real = loss_fn(output_real_label, real_label) # BCE loss\n",
    "    class_loss_real = class_loss_fn(output_real_target, targets) # cross entropy loss\n",
    "\n",
    "    output_fake = netD(fake_image_batch)\n",
    "    output_fake_target = output_fake[:, :10]\n",
    "    output_fake_label = output_fake[:, 10:]\n",
    "    output_fake_label = torch.sigmoid(output_fake_label)\n",
    "\n",
    "    # assert output_fake_target.shape == targets.shape, f\"output_fake_target shape: {output_fake_target.shape} and targets shape: {targets.shape}\"\n",
    "    # assert output_fake_label.shape == fake_label.shape, f\"output_fake_label shape: {output_fake_label.shape} and fake_label shape: {fake_label.shape}\"\n",
    "\n",
    "    loss_fake = loss_fn(output_fake_label, fake_label) # BCE loss\n",
    "    class_loss_fake = class_loss_fn(output_fake_target, targets) # cross entropy loss\n",
    "\n",
    "    loss_real.backward(retain_graph=True)\n",
    "    loss_fake.backward(retain_graph=True)\n",
    "    class_loss_real.backward()\n",
    "    class_loss_fake.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss_real + loss_fake\n",
    "\n",
    "# function to train the netG network\n",
    "def train_generator(optimizer, fake_image_batch, loss_fn, netD, targets, class_loss_fn=nn.CrossEntropyLoss()):\n",
    "    b_size = fake_image_batch.size(0)\n",
    "    real_label = label_real(b_size)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    output = netD(fake_image_batch)\n",
    "\n",
    "    output_target = output[:, :10]  #class\n",
    "    output_label = output[:, 10:]   #real/fake\n",
    "    output_label = torch.sigmoid(output_label)\n",
    "\n",
    "    loss = loss_fn(output_label, real_label)\n",
    "    class_loss = class_loss_fn(output_target, targets)\n",
    "\n",
    "    loss.backward(retain_graph=True)\n",
    "    class_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = netG(10+nz).to(device) # 10 is the number of classes, first\n",
    "netD = netD(10+1).to(device) # 10 is the number of classes, first\n",
    "\n",
    "print(netG)\n",
    "print(netD)\n",
    "\n",
    "# optimizers\n",
    "optim_g = optim.Adam(netG.parameters(), lr=0.0002)\n",
    "optim_d = optim.Adam(netD.parameters(), lr=0.0002)\n",
    "\n",
    "# loss function\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "losses_g = [] # to store netG loss after each epoch\n",
    "losses_d = [] # to store netD loss after each epoch\n",
    "images = [] # to store images generatd by the netG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "load_good_GAN = False\n",
    "# good_GAN_G_path = 'good_models/netG_epoch_800.pth'\n",
    "# good_GAN_D_path = 'good_models/netD_epoch_800.pth'\n",
    "\n",
    "if not load_good_GAN: # RETRAIN THE GAN\n",
    "\n",
    "    # create the noise vector\n",
    "    noise = create_noise(sample_size, nz)\n",
    "    #create an ordered list of targets\n",
    "    targ = torch.zeros(sample_size, 10)\n",
    "    for i in range(sample_size):\n",
    "        targ[i, i%10] = 1\n",
    "    targ = targ.to(device)\n",
    "    gen_input = torch.cat((targ, noise), 1) # concatenate noise and targets\n",
    "    # print(f\"gen_input: {gen_input}\")\n",
    "\n",
    "    netG.train()\n",
    "    netD.train()\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # print(f\"Epoch {epoch} of {epochs}\")\n",
    "\n",
    "        # train the discriminator more in the later epochs\n",
    "        if epoch > 60:\n",
    "            k = 2\n",
    "            if epoch > 80:\n",
    "                k = 4\n",
    "                if epoch > 100:\n",
    "                    k = 6\n",
    "\n",
    "\n",
    "        loss_g = 0.0\n",
    "        loss_d = 0.0\n",
    "        for bi, data in enumerate(train_dataloader):\n",
    "            image_batch, labels = data\n",
    "            #one-hot-encode labels\n",
    "            targets = torch.eye(10)[labels]\n",
    "            image_batch, targets = image_batch.to(device), targets.to(device)\n",
    "            b_size = len(image_batch)\n",
    "            # run the netD for k number of steps\n",
    "            for step in range(k):\n",
    "                noi = create_noise(b_size, nz)\n",
    "                G_input_vector = torch.cat((targets, noi), 1) # concatenate the labels and noise, labels first\n",
    "                # print(input.shape)\n",
    "                fake_image_batch = netG(G_input_vector).detach()\n",
    "                real_image_batch = image_batch\n",
    "                # train the netD network\n",
    "                loss_d += train_discriminator(optim_d, real_image_batch, fake_image_batch, loss_fn, netD, targets)\n",
    "            \n",
    "            noi = create_noise(b_size, nz)\n",
    "            G_input_vector = torch.cat((targets, noi), 1) # concatenate the labels and noise, labels first\n",
    "            fake_image_batch = netG(G_input_vector)\n",
    "            # train the netG network\n",
    "            loss_g += train_generator(optim_g, fake_image_batch, loss_fn, netD, targets)\n",
    "\n",
    "        # create the final fake image_batch for the epoch\n",
    "        generated_img = netG(gen_input).cpu().detach()\n",
    "        # make the images as grid\n",
    "        generated_img = make_grid(generated_img)\n",
    "        # save the generated torch tensor models to disk\n",
    "        save_generator_image(generated_img, f\"data/training/ACgen_img{epoch}.png\")\n",
    "        images.append(generated_img)\n",
    "        epoch_loss_g = loss_g / bi # total netG loss for the epoch\n",
    "        epoch_loss_d = loss_d / bi # total netD loss for the epoch\n",
    "        losses_g.append(epoch_loss_g)\n",
    "        losses_d.append(epoch_loss_d)\n",
    "        #print(f\"netG loss: {epoch_loss_g:.8f}, netD loss: {epoch_loss_d:.8f}\")\n",
    "\n",
    "    print('DONE TRAINING')\n",
    "    torch.save(netG.state_dict(), f'good_models/ACGAN_generator_{epochs}.pth')\n",
    "    torch.save(netD.state_dict(), f'good_models/ACGAN_discriminator_{epochs}.pth')\n",
    "    #save losses\n",
    "    with open(f'data/training/losses_acg_{epochs}.pkl', 'wb') as f:\n",
    "        pickle.dump(losses_g, f)\n",
    "    with open(f'data/training/losses_acd_{epochs}.pkl', 'wb') as f:\n",
    "        pickle.dump(losses_d, f)\n",
    "\n",
    "else:\n",
    "    netG.load_state_dict(torch.load(f'good_models/ACGAN_generator_{epochs}.pth'))\n",
    "    netD.load_state_dict(torch.load(f'good_models/ACGAN_discriminator_{epochs}.pth'))\n",
    "    #load losses\n",
    "    with open(f'data/training/losses_acg_{epochs}.pkl', 'rb') as f:\n",
    "        losses_g = pickle.load(f)\n",
    "    with open(f'data/training/losses_acd_{epochs}.pkl', 'rb') as f:\n",
    "        losses_d = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the generated images as GIF file\n",
    "imgs = [np.array(to_pil_image(img)) for img in images]\n",
    "imageio.mimsave('images/ACgan/generator_images.gif', imgs)\n",
    "\n",
    "# plot and save the netG and netD loss\n",
    "plt.figure()\n",
    "plt.plot(losses_g, label='netG loss')\n",
    "plt.plot(losses_d, label='netD Loss')\n",
    "plt.legend()\n",
    "plt.savefig('images/ACgan/losses.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## real vs fake\n",
    "# Grab a batch of real images from the dataloader\n",
    "real_batch = next(iter(train_dataloader))\n",
    "\n",
    "# Plot the real images\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(torchvision.utils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "# Plot the fake images from the last epoch\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(images[-1],(1,2,0)))\n",
    "plt.show()\n",
    "\n",
    "# save the generated images\n",
    "fig.savefig('images/ACgan/gan_real_vs_fake_images.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "#%%capture\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in images]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fd69f43f58546b570e94fd7eba7b65e6bcc7a5bbc4eab0408017d18902915d69"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
