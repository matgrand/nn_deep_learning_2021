{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational autoencoder / GAN / SimCLR\n",
    "- 2 pt: implement and test variational (convolutional) autoencoder or GAN or SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # plotting library\n",
    "import numpy as np # this module is useful to work with numerical arrays\n",
    "import pandas as pd # this module is useful to work with tabular data\n",
    "import random # this module will be used to select random samples from a collection\n",
    "import os # this module will be used just to create directories in the local filesystem\n",
    "from tqdm import tqdm # this module is useful to plot progress bars\n",
    "from sklearn.model_selection import KFold # this module is useful to split data into training and test sets\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preliminaries\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\") # uncomment this line to run on CPU\n",
    "print(device)\n",
    "\n",
    "## Dataset\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,    \n",
    "    #transform = transforms.ToTensor(),                     \n",
    "    download = True           \n",
    ")\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root = 'data', \n",
    "    train = False, \n",
    "    #transform = transforms.ToTensor(),\n",
    "    download = True\n",
    ")\n",
    "\n",
    "label_names=[f'{i}' for i in range(10)]\n",
    "num_labels = len(label_names)\n",
    "\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)) # normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "# apply the transforms to the training and test data\n",
    "train_data.transform = transform\n",
    "test_data.transform = transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Loader\n",
    "batch_size = 128\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "figure = plt.figure(figsize=(10, 8))\n",
    "cols, rows = 5, 5\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_data), size=(1,)).item()\n",
    "    img, label = train_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(label)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "look at this https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "consider adding batch normalization to generator and discriminator\n",
    "consider adding leakyrelu and too discr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model definition\n",
    "#consider using \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ouput_size=11 ): # 10 for one-hot encoded label + 1 for real/fake\n",
    "        super().__init__()\n",
    "        ### Convolutional section\n",
    "        self.discriminator_cnn = nn.Sequential(\n",
    "            #normalization layer\n",
    "            nn.Conv2d(in_channels= 1, out_channels=32, kernel_size=3, \n",
    "                      stride=2, padding=1, bias=False),\n",
    "            #nn.BatchNorm2d(8),\n",
    "            nn.LeakyReLU(True),\n",
    "            # Second convolutional layer\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, \n",
    "                      stride=2, padding=1, bias=False),\n",
    "            #nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(True),\n",
    "            # Third convolutional layer\n",
    "            nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, \n",
    "                      stride=2, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(True),\n",
    "        )\n",
    "        ### Flatten layer\n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        ### Linear section\n",
    "        self.discriminator_lin = nn.Sequential(\n",
    "            # First linear layer\n",
    "            nn.Linear(in_features=32*3*3, out_features=64),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            # Second linear layer\n",
    "            nn.Linear(in_features=64, out_features=32),\n",
    "            nn.LeakyReLU(True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            #third linear layer\n",
    "            nn.Linear(in_features=32, out_features=ouput_size),\n",
    "            #to restrict ouptut between 0 and 1\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        # Apply convolutions\n",
    "        x = self.discriminator_cnn(x)\n",
    "        # Flatten\n",
    "        x = self.flatten(x)\n",
    "        # # Apply linear layers\n",
    "        x = self.discriminator_lin(x)\n",
    "        return x\n",
    "\n",
    "#consider adding batch normalization to generator \n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size = 12): #10 for one-hot encoded label, + 2 for noise\n",
    "        super().__init__()\n",
    "        ### Linear section\n",
    "        self.generator_lin = nn.Sequential(\n",
    "            # # First linear layer\n",
    "            # nn.Linear(in_features=input_size, out_features=64),\n",
    "            # #nn.BatchNorm1d(64),\n",
    "            # nn.LeakyReLU(True),\n",
    "            # nn.Dropout(p=0.5),\n",
    "            # # Second linear layer\n",
    "            # nn.Linear(in_features=64, out_features=128),\n",
    "            # #nn.BatchNorm1d(128),\n",
    "            # nn.ReLU(True),\n",
    "            # nn.Dropout(p=0.5),\n",
    "            # Second linear layer\n",
    "            nn.Linear(in_features=input_size, out_features=3*3*32), #128\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        ### Unflatten\n",
    "        self.unflatten = nn.Unflatten(dim=1, unflattened_size=(32, 3, 3))\n",
    "        ### Convolutional section\n",
    "        self.generator_conv = nn.Sequential(\n",
    "            # First transposed convolution\n",
    "            nn.ConvTranspose2d(in_channels=32, out_channels=16, kernel_size=3, \n",
    "                               stride=2, output_padding=0, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(True),\n",
    "            # Second transposed convolution\n",
    "            nn.ConvTranspose2d(in_channels=16, out_channels=8, kernel_size=3, \n",
    "                               stride=2, padding=1, output_padding=1, bias=False),\n",
    "            #nn.BatchNorm2d(8),\n",
    "            nn.ReLU(True),\n",
    "            # Third transposed convolution\n",
    "            nn.ConvTranspose2d(in_channels=8, out_channels=1, kernel_size=3, \n",
    "                               stride=2, padding=1, output_padding=1, bias=False),\n",
    "\n",
    "        ) \n",
    "    def forward(self, x):\n",
    "        # Apply linear layers\n",
    "        x = self.generator_lin(x)\n",
    "        # Unflatten\n",
    "        x = self.unflatten(x)\n",
    "        # Apply transposed convolutions\n",
    "        x = self.generator_conv(x)\n",
    "        # Apply a sigmoid to force the output to be between 0 and 1 (valid pixel values)\n",
    "        #x = torch.sigmoid(x)\n",
    "        x = torch.tanh(x) #tanh for images [-1, 1]\n",
    "        return x\n",
    "        \n",
    "\n",
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "noise_size = 20\n",
    "\n",
    "#initialize the discriminator and generator\n",
    "netD = Discriminator(ouput_size=1).to(device) #1 for real/fake let's start easy\n",
    "netG = Generator(input_size=noise_size).to(device) #just noise, let's start easy\n",
    "\n",
    "netD.apply(weights_init)\n",
    "netG.apply(weights_init)\n",
    "\n",
    "## testing I/O\n",
    "#2 element vector with random noise\n",
    "noise = torch.randn(batch_size, noise_size, device=device) #1 will be batch_size\n",
    "# one hot encoding of label \"3\"\n",
    "label = torch.zeros(batch_size, num_labels, device=device)\n",
    "label[:, 3] = 1\n",
    "#concatenate noise and label\n",
    "input = torch.cat((noise, label), 1)\n",
    "input = noise\n",
    "#print input shape\n",
    "print(f\"genrator input shape: {input.shape}\")\n",
    "fake_img = netG(input)\n",
    "print(f\"fake_img shape: {fake_img.shape}\")\n",
    "output = netD(fake_img)\n",
    "print(f\"output shape: {output.shape}\") #(1, 11) 10 classes + 1 for real/fake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea for training: \n",
    "\n",
    "\n",
    "The best idea is to implement the original paper for GANs https://proceedings.neurips.cc/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf, let's be real\n",
    "other useful links:\n",
    "- https://developers.google.com/machine-learning/gan/loss\n",
    "- https://github.com/soumith/ganhacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateD(netD, real_img_batch, fake_img_batch, loss_fn, optimizerD):\n",
    "    ############################\n",
    "    # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "    ###########################\n",
    "    ## Train with all-real batch\n",
    "    netD.zero_grad()\n",
    "    # Forward pass real batch through D\n",
    "    output = netD(real_img_batch)\n",
    "    # Calculate loss on all-real batch\n",
    "    target = torch.full((b_size, 1), real_target, device=device, dtype=torch.float)\n",
    "    errD_real = loss_fn(output, target)\n",
    "    # Calculate gradients for D in backward pass\n",
    "    errD_real.backward()\n",
    "    D_x = output.mean().item()\n",
    "\n",
    "    ## Train with all-fake batch\n",
    "    # Classify all fake batch with D\n",
    "    output = netD(fake_img_batch.detach())\n",
    "    # Calculate D's loss on the all-fake batch\n",
    "    target = torch.full((b_size, 1), fake_target, device=device, dtype=torch.float)\n",
    "    errD_fake = loss_fn(output, target)\n",
    "    # Calculate the gradients for this batch\n",
    "    errD_fake.backward()\n",
    "    D_G_z1 = output.mean().item()\n",
    "    # Add the gradients from the all-real and all-fake batches\n",
    "    errD = errD_real + errD_fake\n",
    "    # Update D\n",
    "    optimizerD.step()\n",
    "    return errD, D_x, D_G_z1\n",
    "\n",
    "def updateG(netG, fake_img_batch, loss_fn, optimizerG):\n",
    "    ############################\n",
    "    # (2) Update G network: maximize log(D(G(z)))\n",
    "    ###########################\n",
    "    netG.zero_grad()\n",
    "    # Since we just updated D, perform another forward pass of all-fake batch through D\n",
    "    output = netD(fake_img_batch)\n",
    "    # Calculate G's loss based on this output\n",
    "    target = torch.full((b_size, 1), real_target, device=device, dtype=torch.float)\n",
    "    errG = loss_fn(output, target)\n",
    "    # Calculate gradients for G\n",
    "    errG.backward()\n",
    "    D_G_z2 = output.mean().item()\n",
    "    # Update G\n",
    "    optimizerG.step()\n",
    "    return errG, D_G_z2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training\n",
    "torch.manual_seed(42)\n",
    "#nets\n",
    "netD = netD.to(device)\n",
    "netG = netG.to(device)\n",
    "\n",
    "# learning rate, based on DCGAN paper\n",
    "g_lr = 0.0002\n",
    "d_lr = 0.00015\n",
    "beta1 = 0.5\n",
    "\n",
    "#loss function\n",
    "#use minimax loss, basically binary cross entropy\n",
    "# real_labels = 1, fake_labels = 0\n",
    "loss_fn = nn.BCELoss() \n",
    "real_target = 1\n",
    "fake_target = 0\n",
    "\n",
    "#batch of latent vectors to visualize progress\n",
    "fixed_noise = torch.randn(64,noise_size, device=device)\n",
    "\n",
    "#optimizers\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = torch.optim.Adam(netD.parameters(), lr=g_lr, betas=(beta1, 0.999))\n",
    "optimizerG = torch.optim.Adam(netG.parameters(), lr=d_lr, betas=(beta1, 0.999))\n",
    "\n",
    "## Training loop\n",
    "num_epochs = 3\n",
    "# Lists to keep track of progress\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# For each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # For each batch in the dataloader\n",
    "    for i, (real_img_batch, label_batch) in enumerate(train_dataloader, 0):\n",
    "        # Format batch\n",
    "        real_img_batch = real_img_batch.to(device)\n",
    "        b_size = real_img_batch.size(0)\n",
    "        # Generate batch of latent vectors\n",
    "        noise = torch.randn(b_size, noise_size, device=device)\n",
    "        # Generate fake image batch with G\n",
    "        fake_img_batch = netG(noise)\n",
    "\n",
    "        ## Train D\n",
    "        errD, D_x, D_G_z1 = updateD(netD, real_img_batch, fake_img_batch, loss_fn, optimizerD)\n",
    "\n",
    "        ## Train G\n",
    "        errG, D_G_z2 = updateG(netG, fake_img_batch, loss_fn, optimizerG)\n",
    "    \n",
    "        # # #balance training\n",
    "        # if epoch >= 1:\n",
    "        #     j = 0\n",
    "        #     while D_x < 0.6 and j < 5: #if discriminator is too bad, train discriminator more\n",
    "        #         noise = torch.randn(real_img_batch.size(0), noise_size, device=device)\n",
    "        #         fake_img_batch = netG(noise)\n",
    "        #         errD, D_x, D_G_z1 = updateD(netD, real_img_batch, fake_img_batch, loss_fn, optimizerD)\n",
    "        #         j += 1\n",
    "        \n",
    "        # Output training stats\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, len(train_dataloader), errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        # Check how the generator is doing by saving G's output on fixed_noise\n",
    "        if (iters % 50 == 0) or ((epoch == num_epochs-1) and (i == len(train_dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "            img_list.append(torchvision.utils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "imo mode collapse is caused by the latent noise being too weak in the generation process.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot losses\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## real vs fake\n",
    "# Grab a batch of real images from the dataloader\n",
    "real_batch = next(iter(train_dataloader))\n",
    "\n",
    "# Plot the real images\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(torchvision.utils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "# Plot the fake images from the last epoch\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cee89b7c6bc96453738565335b56b694d8a30ac65e979633b683f8408c8233c6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 64-bit ('dl_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
